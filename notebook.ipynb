{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "institutional-spider",
   "metadata": {},
   "source": [
    "# Final Year Project\n",
    "## Project 3 - Effectiveness of Skin Cancer Prediction\n",
    "\n",
    "This notebook contains all of the code developed for project 3, completing tasks similar to data scientists working for a dermatologist to investigate whether some characteristics of skin lesions can be reliably measure with a smartphone app.\n",
    "\n",
    "The goal is to measure at least 2 of the following characteristics in a set of skin lesion images; asymmetry, border, and color.\n",
    "\n",
    "Then, we will try to assess how good the measurements are, by predicting the diagnosis of the skin lesions based on these features.\n",
    "\n",
    "We will focus on the **Melanoma** form of skin cancer.\n",
    "\n",
    "Group 3:<br>\n",
    "Crisanna Cornish (ccor@itu.dk)<br>\n",
    "Danielle Dequin (ddeq@itu.dk)<br>\n",
    "Gino Franco Fazzi (gifa@itu.dk)<br>\n",
    "Moneeca Abru Iftikhar Latif (abml@itu.dk)<br>\n",
    "Carl August Wismer (cwis@itu.dk)\n",
    "\n",
    "Created: 07-04-2021<br>\n",
    "Last Modified: 16-04-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-report",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-washer",
   "metadata": {},
   "source": [
    "Data was provided by the ISIC challenge data sets. <br>\n",
    "https://challenge.isic-archive.com/data\n",
    "\n",
    "Codella N, Gutman D, Celebi ME, Helba B, Marchetti MA, Dusza S, Kalloo A, Liopyris K, Mishra N, Kittler H, Halpern A. \"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)\". arXiv: 1710.05006 [cs.CV]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-material",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-comfort",
   "metadata": {},
   "source": [
    "Libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "waiting-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-personal",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-chile",
   "metadata": {},
   "source": [
    "Constants to access data on the directory structure of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worldwide-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = './data/training/' \n",
    "VALID = './data/validation/'\n",
    "TEST = './data/test/'\n",
    "\n",
    "IMG = 'example_image/'\n",
    "SEG = 'example_segmentation/'\n",
    "FEAT = 'features/'\n",
    "TRUTH = 'ground_truth.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-advice",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-equity",
   "metadata": {},
   "source": [
    "Functions created for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "french-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FUNCTIONS FOR MASKED IMAGES\"\"\"\n",
    "\n",
    "def get_boundaries(image):\n",
    "    \"\"\"Function to locate the boundaries of the lesion over the whole image.\n",
    "    Takes a segmentation mask image as argument and returns the upper, lower, left and right boundaries.\"\"\"\n",
    "\n",
    "    mask = np.where(image == 1)\n",
    "    left = min(mask[1])\n",
    "    right = max(mask[1])\n",
    "    upper = min(mask[0])\n",
    "    lower = max(mask[0])\n",
    "    return upper, lower, left, right\n",
    "\n",
    "def get_center(image): # NOT NEEDED ANYMORE ?\n",
    "    \"\"\"Function that takes an image as input, and returns the centerpoint of the lesion.\"\"\"\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    center = ((up+dw)/2, (lt+rt)/2)\n",
    "    return center\n",
    "    \n",
    "def zoom(image):\n",
    "    \"\"\"Function to zoom-in (crop) the lesion from blank space. Takes a segmentation mask image as input,\n",
    "    and returns the rectangle where the lesion is found.\"\"\"\n",
    "\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    rectangle = image[up:dw+1, lt:rt+1]\n",
    "    return rectangle\n",
    "\n",
    "def cuts(image):\n",
    "    \"\"\"Function to perform a double cut (vertical and horizontal) of the lesion. Takes a segmentation mask image as input,\n",
    "    and returns the vertical and horizontal cuts (2 for each dimension). It handles uneven shapes.\"\"\"\n",
    "\n",
    "    center_h = image.shape[0] // 2 # The image shape contains a tuple with height and width (in pixels)\n",
    "    if image.shape[0] % 2 == 0: # If the height is an even number of pixels, the cut returns 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h:,:]\n",
    "    else: # If the height is an uneven number of pixels, the cut has to \"share\" the center, to return 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h+1:,:]\n",
    "        \n",
    "    center_w = image.shape[1] // 2    \n",
    "    if image.shape[1] % 2 == 0:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w:]\n",
    "    else:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w+1:]\n",
    " \n",
    "    return upside, downside, leftside, rightside\n",
    "\n",
    "\n",
    "def test_symmetry(image, rot_deg=30):\n",
    "    \"\"\"Function to test the symmetry of an image. Takes a segmentation mask image and the rotation degree interval and\n",
    "    returns a symmetry score between zero (non-symmetric) to one (completely symmetric).\"\"\"\n",
    "\n",
    "    assert (rot_deg <= 90) and (rot_deg >= 0), \"Rotation degree should be positive and at most 90 deg\"\n",
    "    optimal = 0\n",
    "    \n",
    "    for deg in range(0,91, rot_deg):\n",
    "        rot_image = skimage.transform.rotate(image, deg)\n",
    "        z = zoom(rot_image)\n",
    "        \n",
    "        upside, downside, leftside, rightside = cuts(z)\n",
    "\n",
    "        up_dw = np.sum(np.bitwise_and(upside.astype(int), np.flipud(downside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(upside.astype(int), np.flipud(downside).astype(int)))\n",
    "\n",
    "        lt_rt = np.sum(np.bitwise_and(leftside.astype(int), np.fliplr(rightside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(leftside.astype(int), np.fliplr(rightside).astype(int)))\n",
    "    \n",
    "        symmetry = (up_dw+lt_rt)/2\n",
    "        \n",
    "        if symmetry > optimal: optimal = symmetry\n",
    "\n",
    "    return symmetry\n",
    "    \n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Function to convert a RGB image to grayscale.\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def crop(image, mask, resize=True, warning=True):\n",
    "    if image.shape[:2] != mask.shape[:2]:\n",
    "        if warning:\n",
    "            print(\"Image and Mask must have the same size. OPERATION CANCELLED.\")\n",
    "        else: return\n",
    "    else:\n",
    "        img = image.copy()\n",
    "        img[mask==0] = 0\n",
    "\n",
    "        if resize:\n",
    "            u,d,l,r = get_boundaries(mask)\n",
    "            img = img[u:d,l:r,...]\n",
    "        return img\n",
    "\n",
    "def color_std(image):\n",
    "    \"\"\"A function that takes an image as input, computes and returns the average standard deviation of all the\n",
    "    rgb color values.\"\"\"\n",
    "    try:\n",
    "        R = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,0]\n",
    "        G = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,1]\n",
    "        B = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,2]\n",
    "        color_std = (np.std(R) + np.std(G) + np.std(B)) /3\n",
    "    except:\n",
    "        color_std = 'NA'\n",
    "    return color_std\n",
    "\n",
    "def check_border(image, border=0.01, tolerance=0.2, warning=True):\n",
    "    \"\"\"Function to check if the lesion might be exceeding the image. Take the following arguments:\n",
    "    - image: segmentation mask image to check.\n",
    "    - border: the percentage of pixels to consider as a border. 10% by default.\n",
    "    - tolerance: the percentage of tolerance for a lesion to be at the border of the image. 20% by default.\n",
    "    - warning: boolean to indicate if a textual warning should be issue when checking the border. True by default.\"\"\"\n",
    "    h = int(image.shape[0] * border)\n",
    "    w = int(image.shape[1] * border)\n",
    "    up = (np.sum(image[h,:]) / image.shape[1]) > tolerance\n",
    "    dw = (np.sum(image[-h,:]) / image.shape[1]) > tolerance\n",
    "    lt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    rt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    if warning:\n",
    "        if up or dw or lt or rt: return \"This lesion might be overflowing the image\"\n",
    "        else: return \"This lesion does not seem to be overflowing the image\"\n",
    "    else:\n",
    "        return up or dw or lt or rt\n",
    "    \n",
    "\"\"\"\n",
    "#def laydown(image): # I THINK WE MAY NOT NEED THIS\n",
    "#    z = zoom(image)\n",
    "#    u, d, l, r = get_boundaries(z)\n",
    "#    if (d-u) >= (r-l):\n",
    "#        return skimage.transform.rotate(image, 90) \n",
    "#    else: return image\n",
    "        \n",
    "def reverse(image):\n",
    "    new = image.copy()\n",
    "    new[np.where(image == 1)], new[np.where(image == 0)] = 0, 1\n",
    "    return new\n",
    "\"\"\"\n",
    "\n",
    "def masker(image, sens):\n",
    "    '''Takes image, converts to a grayscale image, and returns a masked \n",
    "    image that only shows values below the sensitivity given as input.'''\n",
    "    \n",
    "    gray = rgb2gray(image) # Create grayscale image\n",
    "    img2 = gray < sens # **This level needs manually adjusting, also need to be able to automate**\n",
    "    \n",
    "    # use plt.imshow(masker(image,sens), cmap='gray') to see image\n",
    "    \n",
    "    return img2.astype(int)\n",
    "\n",
    "def dimensions(mask1):\n",
    "    '''calculates height(max) and width(90 deg to height)\n",
    "        returns height, width, rotated mask image, degree of rotation'''\n",
    "    pixels_in_col = np.max(np.sum(mask1, axis=0))\n",
    "\n",
    "    rot = 0\n",
    "    max_col = 0\n",
    "    rot_max = 0\n",
    "    for _ in range(9):\n",
    "        rot_im = transform.rotate(mask1,rot)\n",
    "        pixels_in_col = np.max(np.sum(rot_im, axis=0))\n",
    "        if pixels_in_col > max_col:\n",
    "            max_col = pixels_in_col\n",
    "            rot_max = rot\n",
    "            pixels_in_row = np.max(np.sum(rot_im, axis=1))\n",
    "        rot += 10\n",
    "\n",
    "    return max_col, pixels_in_row, rot_max\n",
    "\n",
    "def measure_area_perimeter(mask, option=1):\n",
    "    \"\"\"A function that takes either a segmented image or perimeter \n",
    "    image as input, and calculates the length of the perimeter of a lesion.\"\"\"\n",
    "    \n",
    "    # Measure area: the sum of all white pixels in the mask image\n",
    "    area = np.sum(mask)\n",
    "\n",
    "    # Measure perimeter: first find which pixels belong to the perimeter.\n",
    "    if option == 1:\n",
    "        struct_el = morphology.disk(1)\n",
    "        mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "        image_perimeter = mask - mask_eroded\n",
    "\n",
    "        # Now we have the perimeter image, the sum of all white pixels in it\n",
    "        perimeter = np.sum(image_perimeter)\n",
    "    else:\n",
    "        perimeter = measure.perimeter(mask)\n",
    "        \n",
    "\n",
    "    return area, perimeter\n",
    "\n",
    "def predict(bi_image): # Predict might be a little confusing ?\n",
    "    \n",
    "    area = np.sum(bi_image)\n",
    "    _, peri = perimeter(bi_image)\n",
    "    \n",
    "    area_from_peri = pi*((peri/(2*pi))**2)\n",
    "    peri_from_area = 2*pi*sqrt(area/pi)\n",
    "    \n",
    "    return area, area_from_peri, peri, peri_from_area  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-thermal",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-thursday",
   "metadata": {},
   "source": [
    "(NOTE) Here we could show how we visualize a couple of images and masks to get familiar with the images and its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-night",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "geographic-terrorism",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-clarity",
   "metadata": {},
   "source": [
    "(NOTE) We load and access the metadata included in our source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acquired-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {} # A main dictionary will hold our different labels datasets\n",
    "\n",
    "df['train'] = {'path': TRAIN, 'label': pd.read_csv(TRAIN + TRUTH, index_col='image_id')}\n",
    "df['validation'] = {'path': VALID, 'label': pd.read_csv(VALID + TRUTH, index_col='image_id')}\n",
    "df['test'] = {'path': TEST, 'label': pd.read_csv(TEST + TRUTH, index_col='image_id')}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-density",
   "metadata": {},
   "source": [
    "## Dataset Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-biotechnology",
   "metadata": {},
   "source": [
    "#### Figure compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-latex",
   "metadata": {},
   "source": [
    "In order to work more efficiently, we decide to crop the images to reduce their dimensions to the part of the image that contains the lesion. For this, we will use our segmented masks, as following: the color images will be croped to the rectangle where the lesion is, and saving the new image with reduced dimensions. This process must be done only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respiratory-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This operation may take several minutes. Do you wish to continue: (Yes/No) n\n",
      "\n",
      "----- PLEASE BE PATIENT -----\n",
      "\n",
      "OPERATION CANCELLED\n"
     ]
    }
   ],
   "source": [
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    i = 1\n",
    "    for k, v in df.items():\n",
    "        for img_id in v['label'].index:\n",
    "            imgpath = v['path'] + IMG + img_id + '.jpg'\n",
    "            mskpath = v['path'] + SEG + img_id + '_segmentation.png'\n",
    "            img = plt.imread(imgpath)\n",
    "            msk = plt.imread(mskpath)\n",
    "            new = crop(img, msk, warning=False)\n",
    "            if new is None:\n",
    "                pass\n",
    "            else: plt.imsave(imgpath, new)\n",
    "            print(f'\\rResizing image # {i}', end='\\r')\n",
    "            i += 1\n",
    "            \n",
    "else: print(\"OPERATION CANCELLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-contract",
   "metadata": {},
   "source": [
    "### We check for lesions overflowing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inappropriate-friday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ISIC_0000000', 'ISIC_0000001', 'ISIC_0000002', 'ISIC_0000003',\n",
       "       'ISIC_0000004', 'ISIC_0000006', 'ISIC_0000007', 'ISIC_0000008',\n",
       "       'ISIC_0000009', 'ISIC_0000010',\n",
       "       ...\n",
       "       'ISIC_0015189', 'ISIC_0015190', 'ISIC_0015200', 'ISIC_0015204',\n",
       "       'ISIC_0015219', 'ISIC_0015220', 'ISIC_0015233', 'ISIC_0015260',\n",
       "       'ISIC_0015284', 'ISIC_0015295'],\n",
       "      dtype='object', name='image_id', length=2000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train']['label'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "automatic-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./to_check.csv', 'w') as outfile:\n",
    "    outfile.write('image_id'+','+'from Dataset'+'\\n')\n",
    "    for k, data in df.items():\n",
    "            for img_id in data['label'].index:\n",
    "                img = plt.imread(data['path'] + SEG + img_id + '_segmentation.png') \n",
    "                if check_border(img, warning=False) == True:\n",
    "                    outfile.write(img_id+','+data['path']+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-syndication",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-criminal",
   "metadata": {},
   "source": [
    "(NOTE) We proceed to extract features of interest for our predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-validity",
   "metadata": {},
   "source": [
    "#### Asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-affiliate",
   "metadata": {},
   "source": [
    "To test for asymmetry we run a function to calculate a score based on how similar an image is when cut horizontally and vertically. We assign a score between 0 (non asymmetric) and 1 (totally asymmetric) for both cuts, and we take the average to convey a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "frequent-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which dataset to calculate? [train, validation, test] test\n",
      "How many batches? 4\n",
      "Do batch # 2\n",
      "This operation may take several minutes. Do you wish to continue: (Yes/No) y\n",
      "Do you wish to overwrite the /symmetry.csv file?: (Yes/No) y\n",
      "\n",
      "----- PLEASE BE PATIENT -----\n",
      "\n",
      "Calculating symmetry: 100.00%\r"
     ]
    }
   ],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /symmetry.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        symmetry = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating symmetry: {ptg:.2%}', end='\\r')\n",
    "            symmetry[ix] = test_symmetry(image)\n",
    "            i += 1\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'symmetry_{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'symmetry'+'\\n')\n",
    "            for k, v in symmetry.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-homeless",
   "metadata": {},
   "source": [
    "#### Border (Compactness method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "express-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which dataset to calculate? [train, validation, test] test\n",
      "How many batches? 1\n",
      "Do batch # 1\n",
      "This operation may take several minutes. Do you wish to continue: (Yes/No) y\n",
      "Do you wish to overwrite the /compactness.csv file?: (Yes/No) y\n",
      "\n",
      "----- PLEASE BE PATIENT -----\n",
      "\n",
      "Calculating compactness: 100.00%\r"
     ]
    }
   ],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /compactness.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        compactness = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating compactness: {ptg:.2%}', end='\\r')\n",
    "            area, per = measure_area_perimeter(image, option=2)\n",
    "            compactness[ix] = (4* math.pi * area) / (per**2)\n",
    "            i += 1\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'compactness_{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'compactness'+'\\n')\n",
    "            for k, v in symmetry.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-paper",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-laptop",
   "metadata": {},
   "source": [
    "(NOTE) Should we do a color analysis or focus on shape features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-pride",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "turned-dryer",
   "metadata": {},
   "source": [
    "#### Eccentricity -> MAYBE WE SHOULD DELETE THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-newark",
   "metadata": {},
   "source": [
    "(NOTE) Maybe? NEEDS TO USE A CORRECT MAJOR AXIS AND MINOR AXIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "REWRITE = input(\"Do you wish to overwrite the /features/eccentricity.csv file?: (Yes/No) \")\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    eccentricity = {}\n",
    "    i = 1\n",
    "    for ix, row in df[:10].iterrows():\n",
    "        file_path = SEG_PATH + str(ix) + \"_segmentation.png\"\n",
    "        image = plt.imread(file_path)\n",
    "        \n",
    "        ptg = round(i / len(df.index)*100,2)\n",
    "        print(f'\\rCalculating eccentricity: {ptg}%', end='\\r')\n",
    "        up, dw, lt, rt = get_boundaries(image)\n",
    "        h, w = dw-up, rt-lt\n",
    "        short = min(h, w)\n",
    "        long = max(h, w)\n",
    "        eccentricity[ix] = short/long\n",
    "        i += 1\n",
    "else: print(\"OPERATION CANCELLED\")\n",
    "    \n",
    "if REWRITE.lower().startswith(\"y\"):\n",
    "    with open(FEAT_PATH + 'eccentricity.csv', 'w') as outfile:\n",
    "        outfile.write('image_id'+','+'eccentricity'+'\\n')\n",
    "        for k, v in compactness.items():\n",
    "            line = k +','+str(v)\n",
    "            outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-relation",
   "metadata": {},
   "source": [
    "### Aggregating features to datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-present",
   "metadata": {},
   "source": [
    "We will now add the recently extracted features to our main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eastern-hamburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='symmetry'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "feat_symmetry = pd.read_csv(FEAT_PATH + 'symmetry.csv', index_col='image_id') \n",
    "feat_compactness = pd.read_csv(FEAT_PATH + 'compactness.csv', index_col='image_id')\n",
    "df = labels.merge(feat_symmetry, how = 'inner', on = 'image_id').merge(feat_compactness, how = 'inner', on = 'image_id')\n",
    "\n",
    "# Transform binary columns into labels\n",
    "label = []\n",
    "for ix, row in df.iterrows():\n",
    "    if row['melanoma'] == 1:\n",
    "        label.append('Melanoma')\n",
    "    elif row['seborrheic_keratosis'] == 1:\n",
    "        label.append('Keratosis')\n",
    "    else:\n",
    "        label.append('Non-Cancer')\n",
    "df['label'] = label\n",
    "df.drop('melanoma', axis=1, inplace=True)\n",
    "df.drop('seborrheic_keratosis', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-lebanon",
   "metadata": {},
   "source": [
    "### Analysis of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alike-subject",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-microwave",
   "metadata": {},
   "source": [
    "#### Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-chuck",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-atlas",
   "metadata": {},
   "source": [
    "#### Feature scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-ratio",
   "metadata": {},
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-chile",
   "metadata": {},
   "source": [
    "#### Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-browse",
   "metadata": {},
   "source": [
    "#### Model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
