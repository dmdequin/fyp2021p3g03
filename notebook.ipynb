{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e9efd7",
   "metadata": {},
   "source": [
    "# First Year Project\n",
    "## Project 3 - Effectiveness of Skin Cancer Prediction\n",
    "\n",
    "This notebook contains all of the code developed for project 3, completing tasks similar to data scientists working for a dermatologist to investigate whether some characteristics of skin lesions can be reliably measured with a smartphone app.\n",
    "\n",
    "The goal is to measure the following characteristics in a set of skin lesion images; asymmetry, border, and color.\n",
    "\n",
    "Then, we will try to assess how reliable the measurements are at predicting diagnosis.\n",
    "\n",
    "We will focus on the **Melanoma** form of skin cancer.\n",
    "\n",
    "Group 3:<br>\n",
    "Crisanna Cornish (ccor@itu.dk)<br>\n",
    "Danielle Dequin (ddeq@itu.dk)<br>\n",
    "Gino Franco Fazzi (gifa@itu.dk)<br>\n",
    "Moneeca Abru Iftikhar Latif (abml@itu.dk)<br>\n",
    "Carl August Wismer (cwis@itu.dk)\n",
    "\n",
    "Created: 07-04-2021<br>\n",
    "Last Modified: 23-04-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e83455",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e858e5",
   "metadata": {},
   "source": [
    "Data was provided by the ISIC challenge data sets. <br>\n",
    "https://challenge.isic-archive.com/data\n",
    "\n",
    "Codella N, Gutman D, Celebi ME, Helba B, Marchetti MA, Dusza S, Kalloo A, Liopyris K, Mishra N, Kittler H, Halpern A. \"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)\". arXiv: 1710.05006 [cs.CV]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d4aaa",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d098c09",
   "metadata": {},
   "source": [
    "Libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e624e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic libraries for array calculations and dataframes\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#Image processing\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "#Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report,\\\n",
    "confusion_matrix, accuracy_score, plot_confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885d195",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2f9bb",
   "metadata": {},
   "source": [
    "Constants to access data on the directory structure of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d19b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = './data/training/' \n",
    "VALID = './data/validation/'\n",
    "TEST = './data/test/'\n",
    "\n",
    "IMG = 'example_image/'\n",
    "SEG = 'example_segmentation/'\n",
    "FEAT = 'features/'\n",
    "TRUTH = 'ground_truth.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4b342",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0b714",
   "metadata": {},
   "source": [
    "Functions created for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundaries(image):\n",
    "    \"\"\"Function to locate the boundaries of the lesion over the whole image.\n",
    "    Takes a segmentation mask image as argument and returns the upper, lower, left and right boundaries.\"\"\"\n",
    "\n",
    "    mask = np.where(image == 1)\n",
    "    left = min(mask[1])\n",
    "    right = max(mask[1])\n",
    "    upper = min(mask[0])\n",
    "    lower = max(mask[0])\n",
    "    return upper, lower, left, right\n",
    "    \n",
    "def zoom(image):\n",
    "    \"\"\"Function to zoom-in (crop) the lesion from blank space. Takes a segmentation mask image as input,\n",
    "    and returns the rectangle where the lesion is found.\"\"\"\n",
    "\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    rectangle = image[up:dw+1, lt:rt+1]\n",
    "    return rectangle\n",
    "\n",
    "def cuts(image):\n",
    "    \"\"\"Function to perform a double cut (vertical and horizontal) of the lesion. Takes a segmentation mask image as input,\n",
    "    and returns the vertical and horizontal cuts (2 for each dimension). It handles uneven shapes.\"\"\"\n",
    "\n",
    "    center_h = image.shape[0] // 2 # The image shape contains a tuple with height and width (in pixels)\n",
    "    if image.shape[0] % 2 == 0: # If the height is an even number of pixels, the cut returns 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h:,:]\n",
    "    else: # If the height is an uneven number of pixels, the cut has to \"share\" the center, to return 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h+1:,:]\n",
    "        \n",
    "    center_w = image.shape[1] // 2    \n",
    "    if image.shape[1] % 2 == 0:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w:]\n",
    "    else:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w+1:]\n",
    "    return upside, downside, leftside, rightside\n",
    "\n",
    "\n",
    "def test_symmetry(image, rot_deg=5):\n",
    "    \"\"\"Function to test the symmetry of an image. Takes a segmentation mask image and\n",
    "    the rotation degree interval and returns a symmetry score between zero (non-symmetric)\n",
    "    to one (completely symmetric).\"\"\"\n",
    "\n",
    "    assert (rot_deg <= 90) and (rot_deg >= 0), \"Rotation degree should be positive and at most 90 deg\"\n",
    "    optimal = 0\n",
    "    \n",
    "    for deg in range(0,91, rot_deg):\n",
    "        rot_image = skimage.transform.rotate(image, deg, resize=True)\n",
    "        z = zoom(rot_image)\n",
    "        \n",
    "        upside, downside, leftside, rightside = cuts(z)\n",
    "\n",
    "        #divide sum of pixels that are the same by sum of pixels that are different\n",
    "        up_dw = np.sum(np.bitwise_and(upside.astype(int), np.flipud(downside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(upside.astype(int), np.flipud(downside).astype(int)))\n",
    "\n",
    "        lt_rt = np.sum(np.bitwise_and(leftside.astype(int), np.fliplr(rightside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(leftside.astype(int), np.fliplr(rightside).astype(int)))\n",
    "    \n",
    "        symmetry = (up_dw+lt_rt)/2\n",
    "        \n",
    "        if symmetry > optimal: optimal = symmetry #update optimal if a better symmetry is found\n",
    "\n",
    "    return optimal\n",
    "    \n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Function to convert a RGB image to grayscale.\"\"\"\n",
    "    \n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def crop(image, mask, resize=True, warning=True):\n",
    "    \"\"\"Function to crop an image. It takes a color image and its segmented mask as arguments and returns\n",
    "    a new image where the lesion is present in color, and the background is empty.\n",
    "    The resize argument (True by default) will reduce the image to the minimum rectangle containing the\n",
    "    lesion.\n",
    "    The warning argument (True by default) will raise an exception if the image and the mask don't have\n",
    "    the same dimensions.\"\"\"\n",
    "    \n",
    "    if image.shape[:2] != mask.shape[:2]:\n",
    "        if warning:\n",
    "            print(\"Image and Mask must have the same size. OPERATION CANCELLED.\")\n",
    "            \n",
    "        else: return\n",
    "    else:\n",
    "        img = image.copy()\n",
    "        img[mask==0] = 0\n",
    "\n",
    "        if resize:\n",
    "            u,d,l,r = get_boundaries(mask)\n",
    "            img = img[u:d,l:r,...]\n",
    "            \n",
    "        return img\n",
    "\n",
    "def color_std(image):\n",
    "    \"\"\"A function that takes an image as input, computes and returns the average standard deviation of all the\n",
    "    rgb color values.\"\"\"\n",
    "    \n",
    "    R = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,0]\n",
    "    G = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,1]\n",
    "    B = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,2]\n",
    "    color_std = (np.std(R) + np.std(G) + np.std(B)) /3\n",
    "\n",
    "    return color_std\n",
    "\n",
    "def check_border(image, border=0.01, tolerance=0.2, warning=True):\n",
    "    \"\"\"Function to check if the lesion might be exceeding the image. Take the following arguments:\n",
    "    - image: segmentation mask image to check.\n",
    "    - border: the percentage of pixels to consider as a border. 10% by default.\n",
    "    - tolerance: the percentage of tolerance for a lesion to be at the border of the image. 20% by default.\n",
    "    - warning: boolean to indicate if a textual warning should be issue when checking the border. True by default.\"\"\"\n",
    "    \n",
    "    h = int(image.shape[0] * border)\n",
    "    w = int(image.shape[1] * border)\n",
    "    up = (np.sum(image[h,:]) / image.shape[1]) > tolerance\n",
    "    dw = (np.sum(image[-h,:]) / image.shape[1]) > tolerance\n",
    "    lt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    rt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    if warning:\n",
    "        if up or dw or lt or rt: return \"This lesion might be overflowing the image\"\n",
    "        else: return \"This lesion does not seem to be overflowing the image\"\n",
    "    else:\n",
    "        return up or dw or lt or rt\n",
    "\n",
    "def measure_area_perimeter(mask):\n",
    "    \"\"\"A function that takes either a segmented image or perimeter \n",
    "    image as input, and calculates the length of the perimeter of a lesion.\"\"\"\n",
    "    \n",
    "    # Measure area: the sum of all white pixels in the mask image\n",
    "    area = np.sum(mask)\n",
    "\n",
    "    # Measure perimeter: first find which pixels belong to the perimeter.\n",
    "    perimeter = measure.perimeter(mask)\n",
    "    \n",
    "    return area, perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7791807",
   "metadata": {},
   "source": [
    "## Directories Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9e29d",
   "metadata": {},
   "source": [
    "We create a main container (dictionary) for our datasets. Each dataset will contain a relative path to itself and a \"label\" dataframe.\n",
    "\n",
    "<h4><center>DF</center></h4>            \n",
    "<h4><center>|</center></h4>\n",
    "<h4><center>TRAIN - VALIDATION - TEST</center></h4>\n",
    "<h4><center>\\ | /</center></h4>\n",
    "<h4><center>|</center></h4>\n",
    "<h4><center>/ | \\</center></h4>\n",
    "<h4><center>PATH - LABEL - FEATURES</center></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {} # A main dictionary will hold our different labels for datasets\n",
    "\n",
    "df['train'] = {'path': TRAIN, 'label': pd.read_csv(TRAIN + TRUTH, index_col='image_id')}\n",
    "df['validation'] = {'path': VALID, 'label': pd.read_csv(VALID + TRUTH, index_col='image_id')}\n",
    "df['test'] = {'path': TEST, 'label': pd.read_csv(TEST + TRUTH, index_col='image_id')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d6bd2",
   "metadata": {},
   "source": [
    "# Image reading, manipulation and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ca020",
   "metadata": {},
   "source": [
    "WARNING: The following cells perform different tasks over the image files, which have been already process. The cells will not execute unless the ENABLE variable is set to TRUE.\n",
    "Note: the feature extraction and has already saved its results to different csv files that can be easily access throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c49b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4512b54",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (Task 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bfbbc2",
   "metadata": {},
   "source": [
    "## Dataset Cleaning and Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8bcf3",
   "metadata": {},
   "source": [
    "#### Figure compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeffe63",
   "metadata": {},
   "source": [
    "In order to work more efficiently, we decide to crop the images to reduce their dimensions to the part of the image that contains the lesion. For this, we will use our segmented masks, as following: the color images will be cropped to the rectangle where the lesion is, and saving the new image with reduced dimensions. This process must be done only once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d86c75",
   "metadata": {},
   "source": [
    "\n",
    "<h5 align=left>Before and After</h4>\n",
    "<table<tr><td><img src=\"./data/example.jpg\" alt=\"Before\" width=\"200px\"></td><td><img src=\"./data/training/example_image/ISIC_0000001.jpg\" alt=\"After\" width=\"200px\"></td></tr></table>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE:\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        i = 1\n",
    "        for k, v in df.items():\n",
    "            for img_id in v['label'].index:\n",
    "                imgpath = v['path'] + IMG + img_id + '.jpg'\n",
    "                mskpath = v['path'] + SEG + img_id + '_segmentation.png'\n",
    "                img = plt.imread(imgpath)\n",
    "                msk = plt.imread(mskpath)\n",
    "                new = crop(img, msk, warning=False)\n",
    "                if new is None:\n",
    "                    pass\n",
    "                else: plt.imsave(imgpath, new)\n",
    "                print(f'\\rResizing image # {i}', end='\\r')\n",
    "                i += 1\n",
    "\n",
    "    else: print(\"OPERATION CANCELLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577890c",
   "metadata": {},
   "source": [
    "### We check for lesions overflowing the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd2aa4",
   "metadata": {},
   "source": [
    "Here we go through the images and find those that are potentially too zoomed in and cut off areas of the border. Since part of this study focused on asymmetry and compactness of lesions, it is necessary to have images that show the entire border. \n",
    "\n",
    "The output is a list of images that are potentially cutting off the border. We then manually went through to verify the quality of the border in the images before excluding them from the model. The exclusion of each image was decided by group agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE:\n",
    "    # We loop through all images applying our automatic border detection function\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        with open('./data/border_check.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'from Dataset'+'\\n')\n",
    "            for k, data in df.items():\n",
    "                    for img_id in data['label'].index:\n",
    "                        img = plt.imread(data['path'] + SEG + img_id + '_segmentation.png') \n",
    "                        if check_border(img, warning=False) == True:\n",
    "                            outfile.write(img_id+','+data['path']+'\\n')\n",
    "    else:\n",
    "        print(\"OPERATION CANCELLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae533d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After careful manual inspection, we read the file and filter the images to be ignored.\n",
    "# We then exclude them from our datasets.\n",
    "\n",
    "visual_inspection = pd.read_csv('./data/border_check.csv')\n",
    "to_be_ignored = visual_inspection[visual_inspection.loc[:,'Visual inspection'] == 'Ignore']\n",
    "mela, kera, non = 0,0,0\n",
    "for ix, row in to_be_ignored.iterrows():\n",
    "    try:\n",
    "        image = row.loc['image_id']\n",
    "        from_dataset = row.loc['from Dataset']\n",
    "        if df[from_dataset]['label'].loc[image,'melanoma'] == 1:\n",
    "            mela += 1\n",
    "        elif df[from_dataset]['label'].loc[image,'seborrheic_keratosis'] == 1:\n",
    "            kera += 1\n",
    "        else: non += 1\n",
    "        df[from_dataset]['label'].drop(image, axis=0, inplace=True)\n",
    "    except:\n",
    "        image = row.loc['image_id']\n",
    "        from_dataset = row.loc['from Dataset']\n",
    "        if df[from_dataset]['label'].loc[image,'melanoma'] == 1:\n",
    "            mela += 1\n",
    "        elif df[from_dataset]['label'].loc[image,'seborrheic_keratosis'] == 1:\n",
    "            kera += 1\n",
    "        else: non += 1\n",
    "            \n",
    "print(f'{to_be_ignored.shape[0]} images excluded from the model.')\n",
    "print(f'{mela} melanomas, {kera} keratosis and {non} benigns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65b6cc",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0621cc54",
   "metadata": {},
   "source": [
    "Here we explore the images to get familiar with them and their attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdeedb",
   "metadata": {},
   "source": [
    "### Load Image and Segmentation Image Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = 'ISIC_0000000'\n",
    "image = plt.imread(df['train']['path']+IMG+IM+'.jpg')\n",
    "seg = plt.imread(df['train']['path']+SEG+IM+'_segmentation.png')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7, 5))\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(seg, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bda11b",
   "metadata": {},
   "source": [
    "### Showing how the zoom function works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d255b8",
   "metadata": {},
   "source": [
    "This shows how the image was cropped so that the border is cut to the edges of the lesion, resulting in the cropped image of the lesion seen above on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(zoom(seg), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b91647",
   "metadata": {},
   "source": [
    "### Convert an image to grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f544cbe",
   "metadata": {},
   "source": [
    "This shows how the rgb2gray function works to convert an image to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db598b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb2gray(image), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978b0f8",
   "metadata": {},
   "source": [
    "### Visualize output of function for Area and Perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d0638",
   "metadata": {},
   "source": [
    "This shows the output of the function that shows area and perimeter of a lesion, as well as a visual display of the perimeter of the lesion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "area, perimeter = measure_area_perimeter(seg)\n",
    "print(f'Area: {area}\\nPerimeter: {perimeter}')\n",
    "\n",
    "struct_el = morphology.disk(1)\n",
    "mask_eroded = morphology.binary_erosion(seg, struct_el)\n",
    "image_perimeter = seg - mask_eroded\n",
    "plt.imshow(image_perimeter, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846997ae",
   "metadata": {},
   "source": [
    "### Output of the cuts function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df07883",
   "metadata": {},
   "source": [
    "The output of this function is then used in the test_symmetry function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,d,l,r = cuts(zoom(seg))\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(5,3), dpi=350)\n",
    "ax1.imshow(u, cmap='gray')\n",
    "ax2.imshow(d, cmap='gray')\n",
    "ax3.imshow(l, cmap='gray')\n",
    "ax4.imshow(r, cmap='gray')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943de392",
   "metadata": {},
   "source": [
    "### Result of the test_symmetry function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_symmetry(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b551ba6c",
   "metadata": {},
   "source": [
    "This lesion shows a 85% symmetry, which lines up well with the visual symmetry of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db747cc9",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba93c6a",
   "metadata": {},
   "source": [
    "We proceed to extract features of interest for our predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a352f",
   "metadata": {},
   "source": [
    "#### Asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7da3ba",
   "metadata": {},
   "source": [
    "To test for asymmetry we run a function to calculate a score based on how similar an image is when cut horizontally and vertically. We assign a score between 0 (completely asymmetric) and 1 (perfect symmetry) for both cuts, and we take the average to convey a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911176a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a test on a circle, where it's symmetry should be 1\n",
    "test_circle = plt.imread('./data/test-black-circle.png') # Load the circle test\n",
    "test_circle = test_circle[:,:,0]\n",
    "print(f'Symmetry test for circle: {test_symmetry(test_circle):.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE:\n",
    "\n",
    "    DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "    if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "        print('OPERATION CANCELLED')\n",
    "    else:\n",
    "        data = df[DATASET]['label']\n",
    "\n",
    "        DoBatch = int(input(\"How many batches? \"))\n",
    "        if DoBatch > data.shape[0]:\n",
    "            DoBatch = data.shape[0]\n",
    "        batch = int(input(\"Do batch # \"))\n",
    "        assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "        WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "        REWRITE = input(\"Do you wish to overwrite the /symmetry.csv file?: (Yes/No) \")\n",
    "        print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "        length = data.shape[0] // DoBatch\n",
    "        start = length * (batch - 1)\n",
    "        end = length * (batch)\n",
    "\n",
    "        if WARN.lower().startswith(\"y\"):\n",
    "            symmetry = {}\n",
    "            i = 1\n",
    "            for ix, row in data[start:end].iterrows():\n",
    "                file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "                image = plt.imread(file_path)\n",
    "\n",
    "                ptg = round(i / length,2)\n",
    "                print(f'\\rCalculating symmetry: {ptg:.2%}', end='\\r')\n",
    "                symmetry[ix] = test_symmetry(image)\n",
    "                i += 1\n",
    "                %xdel image\n",
    "        else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "        if REWRITE.lower().startswith(\"y\"):\n",
    "            with open(df[DATASET]['path'] + FEAT + f'symmetry_{str(batch)}.csv', 'w') as outfile:\n",
    "                outfile.write('image_id'+','+'symmetry'+'\\n')\n",
    "                for k, v in symmetry.items():\n",
    "                    line = k +','+str(v)\n",
    "                    outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8d661",
   "metadata": {},
   "source": [
    "#### Border (Compactness method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4566f16",
   "metadata": {},
   "source": [
    "To test for border smoothness we use the compactness method. Compactness is defined as the ratio of the\n",
    "area of an object to the area of a circle with the same perimeter.\n",
    "The measure takes a maximum value of 1 for a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a test on a circle, where it's compactness should be close to 1\n",
    "circle_area, circle_perimeter = measure_area_perimeter(test_circle)\n",
    "#print(circle_area, circle_perimeter)\n",
    "circle_compactness = (4* math.pi * circle_area) / (circle_perimeter**2)\n",
    "print(f'Compactness test for circle: {circle_compactness:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e4f99",
   "metadata": {},
   "source": [
    "Our compactness function does not capture the real compactness of a circle due to the pixel abstraction of a circle. In the next code we take the theoretical perimeter of the test circle to find the real compactness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a test on a circle, where it's compactness should be close to 1\n",
    "circle_area, _ = measure_area_perimeter(test_circle)\n",
    "theoretical_perimeter = 2 * math.pi * zoom(test_circle).shape[0] //2\n",
    "#print(circle_area, circle_perimeter)\n",
    "circle_compactness = (4* math.pi * circle_area) / (theoretical_perimeter**2)\n",
    "print(f'Compactness test for circle with theoretical perimeter: {circle_compactness:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427373f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE:\n",
    "    DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "    if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "        print('OPERATION CANCELLED')\n",
    "    else:\n",
    "        data = df[DATASET]['label']\n",
    "\n",
    "        DoBatch = int(input(\"How many batches? \"))\n",
    "        if DoBatch > data.shape[0]:\n",
    "            DoBatch = data.shape[0]\n",
    "        batch = int(input(\"Do batch # \"))\n",
    "        assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "        WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "        REWRITE = input(\"Do you wish to overwrite the /compactness.csv file?: (Yes/No) \")\n",
    "        print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "        length = data.shape[0] // DoBatch\n",
    "        start = length * (batch - 1)\n",
    "        end = length * (batch)\n",
    "\n",
    "        if WARN.lower().startswith(\"y\"):\n",
    "            compactness = {}\n",
    "            i = 1\n",
    "            for ix, row in data[start:end].iterrows():\n",
    "                file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "                image = plt.imread(file_path)\n",
    "\n",
    "                ptg = round(i / length,2)\n",
    "                print(f'\\rCalculating compactness: {ptg:.2%}', end='\\r')\n",
    "                area, per = measure_area_perimeter(image)\n",
    "                compactness[ix] = (4* math.pi * area) / (per**2)\n",
    "                i += 1\n",
    "        else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "        if REWRITE.lower().startswith(\"y\"):\n",
    "            with open(df[DATASET]['path'] + FEAT + f'compactness_{str(batch)}.csv', 'w') as outfile:\n",
    "                outfile.write('image_id'+','+'compactness'+'\\n')\n",
    "                for k, v in compactness.items():\n",
    "                    line = k +','+str(v)\n",
    "                    outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb42e24",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ccb83",
   "metadata": {},
   "source": [
    "In order to evaluate the difference in lesion colors, we take the standard deviation for each of the 3 RGB channels of the cropped image (to reduce noise), and then we average the 3 deviations to obtain a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE:\n",
    "    DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "    if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "        print('OPERATION CANCELLED')\n",
    "    else:\n",
    "        data = df[DATASET]['label']\n",
    "\n",
    "        DoBatch = int(input(\"How many batches? \"))\n",
    "        if DoBatch > data.shape[0]:\n",
    "            DoBatch = data.shape[0]\n",
    "        batch = int(input(\"Do batch # \"))\n",
    "        assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "        WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "        REWRITE = input(\"Do you wish to overwrite the /color_deviation.csv file?: (Yes/No) \")\n",
    "        print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "        length = data.shape[0] // DoBatch\n",
    "        start = length * (batch - 1)\n",
    "        end = length * (batch)\n",
    "\n",
    "        if WARN.lower().startswith(\"y\"):\n",
    "            color_deviation = {}\n",
    "            i = 1\n",
    "            for ix, row in data[start:end].iterrows():\n",
    "                file_path = df[DATASET]['path'] + IMG + str(ix) + \".jpg\"\n",
    "                image = plt.imread(file_path)\n",
    "\n",
    "                ptg = round(i / length,2)\n",
    "                print(f'\\rCalculating color deviation: {ptg:.2%}', end='\\r') \n",
    "                color_deviation[ix] = color_std(image)\n",
    "                i += 1\n",
    "        else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "        if REWRITE.lower().startswith(\"y\"):\n",
    "            with open(df[DATASET]['path'] + FEAT + f'color_deviation{str(batch)}.csv', 'w') as outfile:\n",
    "                outfile.write('image_id'+','+'color_deviation'+'\\n')\n",
    "                for k, v in color_deviation.items():\n",
    "                    line = k +','+str(v)\n",
    "                    outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae417b3f",
   "metadata": {},
   "source": [
    "### Aggregating features to datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fddd32",
   "metadata": {},
   "source": [
    "We will now add the recently extracted features to our main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a4d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['symmetry', 'compactness', 'color_deviation']\n",
    "for dataset in df.keys():\n",
    "    for feat in feat_list:\n",
    "        symmetry = pd.read_csv(df[dataset]['path'] + FEAT + 'symmetry.csv', index_col='image_id') \n",
    "        compactness = pd.read_csv(df[dataset]['path'] + FEAT + 'compactness.csv', index_col='image_id')\n",
    "        color_deviation = pd.read_csv(df[dataset]['path'] + FEAT + 'color_deviation.csv', index_col='image_id')\n",
    "        df[dataset]['features'] = symmetry.merge(compactness, how = 'inner', on = 'image_id')\\\n",
    "        .merge(color_deviation, how = 'inner', on = 'image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c900bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train']['features'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6679cf2",
   "metadata": {},
   "source": [
    "### Analysis of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f389e9",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15127b4d",
   "metadata": {},
   "source": [
    "As our features Symmetry and Compactness have a metric between zero and one, we will only scale the color deviation feature to match the same range as the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553adc2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in df.keys():\n",
    "    scaled_color_deviation = []\n",
    "    to_scale = df[dataset]['features'].color_deviation\n",
    "    for i in to_scale.iteritems():\n",
    "        new_x = (i[1] - np.min(to_scale)) /\\\n",
    "        (np.max(to_scale) - np.min(to_scale))\n",
    "        scaled_color_deviation.append(new_x)\n",
    "    df[dataset]['features'].color_deviation = scaled_color_deviation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Dataframe with scaling\n",
    "df['train']['features'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f525c",
   "metadata": {},
   "source": [
    "#### Creating Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6362ef4",
   "metadata": {},
   "source": [
    "We create a \"training set\" by merging the collected features with the labels for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df['train']['label'].merge(df['train']['features'], how = 'inner', on = 'image_id')\n",
    "train_set.drop('seborrheic_keratosis', axis= 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.loc[train_set.melanoma == 1, 'melanoma'] = \"Melanoma\" # Change labels from float to String\n",
    "train_set.loc[train_set.melanoma == 0, 'melanoma'] = \"Non-Melanoma\"\n",
    "train_set.columns = ['label'] + list(train_set.columns)[1:] # Re order columns to match all sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c027ac",
   "metadata": {},
   "source": [
    "#### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c000d27",
   "metadata": {},
   "source": [
    "Since our training set contains 5 times more Non-Melanoma observations than \"Melanoma\", we resample to achieve 1/3 of positive \"Melanoma\" labels and train a more balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "melanoma = train_set.loc[train_set.label == \"Melanoma\"]\n",
    "n = train_set.shape[0]//2 - melanoma.shape[0] # We want 1/3 to be melanoma\n",
    "resample_melanoma = resample(melanoma, n_samples=n, random_state= 0)\n",
    "train_set_rs = train_set.append(resample_melanoma)\n",
    "print(f'The new training set contains now {train_set_rs[train_set_rs.label == \"Melanoma\"].shape[0]}\\\n",
    " Melanoma observations and {train_set_rs[train_set_rs.label != \"Melanoma\"].shape[0]}\\\n",
    " non Melanoma observations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc737012",
   "metadata": {},
   "source": [
    "#### Plotting features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b36488",
   "metadata": {},
   "source": [
    "We plot our features by two with their correspondant kernel density curves to detect patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb9e2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = ['Melanoma', 'Non-Melanoma']\n",
    "cl = ['r','g'] # Colors\n",
    "\n",
    "feat_iter = feat_list.copy()\n",
    "for f1 in feat_iter:\n",
    "    for f2 in feat_iter:\n",
    "        if f1 != f2:\n",
    "        \n",
    "            # Set up 4 subplots and aspect ratios as axis objects using GridSpec:\n",
    "            gs = gridspec.GridSpec(2, 2, width_ratios=[1,3], height_ratios=[3,1])\n",
    "            # Add space between scatter plot and KDE plots to accommodate axis labels:\n",
    "            gs.update(hspace=0.3, wspace=0.3)\n",
    "\n",
    "            fig = plt.figure(figsize=(15,12)) \n",
    "            fig.patch.set_facecolor('white')\n",
    "\n",
    "            ax = plt.subplot(gs[0,1]) # Instantiate scatter plot area and axis range\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_xlabel(f1, fontsize = 14)\n",
    "            ax.set_ylabel(f2, fontsize = 14)\n",
    "            ax.yaxis.labelpad = 10 # adjust space between x and y axes and their labels if needed\n",
    "\n",
    "            axl = plt.subplot(gs[0,0], sharey=ax) # Instantiate left KDE plot area\n",
    "            axl.get_xaxis().set_visible(False) # Hide tick marks and spines\n",
    "            axl.get_yaxis().set_visible(False)\n",
    "            axl.spines[\"right\"].set_visible(False)\n",
    "            axl.spines[\"top\"].set_visible(False)\n",
    "            axl.spines[\"bottom\"].set_visible(False)\n",
    "\n",
    "            axb = plt.subplot(gs[1,1], sharex=ax) # Instantiate bottom KDE plot area\n",
    "            axb.get_xaxis().set_visible(False) # Hide tick marks and spines\n",
    "            axb.get_yaxis().set_visible(False)\n",
    "            axb.spines[\"right\"].set_visible(False)\n",
    "            axb.spines[\"top\"].set_visible(False)\n",
    "            axb.spines[\"left\"].set_visible(False)\n",
    "\n",
    "            axc = plt.subplot(gs[1,0]) # Instantiate legend plot area\n",
    "            axc.axis('off') # Hide tick marks and spines\n",
    "\n",
    "            # For each category in the list...\n",
    "            for l in range(len(labels)):\n",
    "            # Create a sub-table containing only entries matching current category:\n",
    "                st = train_set_rs.loc[train_set_rs['label'] == labels[l]]\n",
    "                # Select first two columns of sub-table as x and y values to be plotted:\n",
    "                x = st[f1].values\n",
    "                y = st[f2].values\n",
    "\n",
    "                # Plot data for each categorical variable as scatter and marginal KDE plots:    \n",
    "                ax.scatter(x,y, color='none', s=100, edgecolor= cl[l], label = labels[l])\n",
    "\n",
    "                kde = stats.gaussian_kde(x)\n",
    "                xx = np.linspace(0, 1, 1000)\n",
    "                axb.plot(xx, kde(xx), color=cl[l])\n",
    "\n",
    "                kde = stats.gaussian_kde(y)\n",
    "                yy = np.linspace(0, 1, 1000)\n",
    "                axl.plot(kde(yy), yy, color=cl[l])\n",
    "\n",
    "            # Copy legend object from scatter plot to lower left subplot and display:\n",
    "            # NB 'scatterpoints = 1' customises legend box to show only 1 handle (icon) per label \n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            axc.legend(handles, labels, scatterpoints = 1, loc = 'center', fontsize = 12)\n",
    "            \n",
    "            #plt.savefig(f'./reports/figures/scatter-density-{f1}-{f2}.png')\n",
    "            plt.show()\n",
    "    feat_iter.remove(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf09e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = train_set_rs.loc[train_set_rs.label == \"Melanoma\"]\n",
    "negative = train_set_rs.loc[train_set_rs.label == \"Non-Melanoma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a8e85",
   "metadata": {},
   "source": [
    "We plot now a 3D scatterplot with all 3 features distinguishing by label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(positive.symmetry.values, positive.compactness.values, positive.color_deviation.values, \\\n",
    "           color='r', label='Melanoma')\n",
    "ax.scatter(negative.symmetry.values, negative.compactness.values, negative.color_deviation.values, \\\n",
    "           color='g', label=\"Non-Melanoma\")\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_zlim(0, 1)\n",
    "ax.set_xlabel(\"Symmetry\", fontsize = 14)\n",
    "ax.set_ylabel(\"Compactness\", fontsize = 14)\n",
    "ax.set_zlabel(\"Color Deviation\", fontsize = 14)\n",
    "ax.yaxis.labelpad = 10 # adjust space between x and y axes and their labels if needed\n",
    "plt.title(\"Melanoma vs Non-Melanoma for all features\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./reports/figures/3D-all-features.png')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dad414",
   "metadata": {},
   "source": [
    "Finally we take a closer look at the distributions of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a931a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(7,5), dpi=350)\n",
    "fig.suptitle(\"Melanoma Vs Non-Melanoma Feature Distributions\")\n",
    "fig.tight_layout()\n",
    "\n",
    "sns.kdeplot(x = 'symmetry', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\",ax=axs[0])\n",
    "sns.kdeplot(x = 'symmetry', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\",ax=axs[0])\n",
    "axs[0].axvline(np.mean(positive.symmetry), ymin= 0, ymax= 0.74, color='r', linestyle = 'dashed')\n",
    "axs[0].axvline(np.mean(negative.symmetry), ymin= 0, ymax= 0.80, color='g', linestyle = 'dashed')\n",
    "axs[0].legend(loc=\"upper left\")\n",
    "\n",
    "sns.kdeplot(x = 'compactness', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\",ax=axs[1])\n",
    "sns.kdeplot(x = 'compactness', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\",ax=axs[1])\n",
    "axs[1].axvline(np.mean(positive.compactness), ymin= 0, ymax= 0.72, color='r', linestyle = 'dashed')\n",
    "axs[1].axvline(np.mean(negative.compactness), ymin= 0, ymax= 0.80, color='g', linestyle = 'dashed')\n",
    "#axs[1].legend(loc=\"upper left\")\n",
    "\n",
    "sns.kdeplot(x = 'color_deviation', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\",ax=axs[2])\n",
    "sns.kdeplot(x = 'color_deviation', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\",ax=axs[2])\n",
    "axs[2].axvline(np.mean(positive.color_deviation), ymin= 0, ymax= 0.77, color='r', linestyle = 'dashed')\n",
    "axs[2].axvline(np.mean(negative.color_deviation), ymin= 0, ymax= 0.88, color='g', linestyle = 'dashed')\n",
    "#axs[2].legend(loc=\"upper right\")\n",
    "\n",
    "#plt.savefig(\"./reports/figures/densitySubplots.png\")\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50948934",
   "metadata": {},
   "source": [
    "From the plots is difficult to see any correlation. We will take each feature by pairs and see if they are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Melanoma, the features have the following correlation coefficients:\\n')\n",
    "feat_iter = feat_list.copy()\n",
    "for f1 in feat_iter:\n",
    "    for f2 in feat_iter:\n",
    "        if f1 != f2:\n",
    "            corr = np.corrcoef(positive[f1], positive[f2])\n",
    "            print(f'Corr. {f1} and {f2}: {corr[0,1]:.2%}')\n",
    "    feat_iter.remove(f1)\n",
    "    \n",
    "print('\\nFor Non-Melanoma, the features have the following correlation coefficients:\\n')\n",
    "feat_iter = feat_list.copy()\n",
    "for f1 in feat_iter:\n",
    "    for f2 in feat_iter:\n",
    "        if f1 != f2:\n",
    "            corr = np.corrcoef(negative[f1], negative[f2])\n",
    "            print(f'Corr. {f1} and {f2}: {corr[0,1]:.2%}')\n",
    "    feat_iter.remove(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77724dd",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c77619",
   "metadata": {},
   "source": [
    "We first create the set with features and labels for validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16942642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Validation Data\n",
    "validation_set = df['validation']['label'].merge(df['validation']['features'],\\\n",
    "                                                 how = 'inner', on = 'image_id')\n",
    "\n",
    "# For Test Data\n",
    "test_set = df['test']['label'].merge(df['test']['features'], how = 'inner', on = 'image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31467008",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for ix, row in validation_set.iterrows():\n",
    "    if row['melanoma'] == 1.0:\n",
    "        labels.append(\"Melanoma\")\n",
    "    else:\n",
    "        labels.append(\"Non-Melanoma\")\n",
    "        \n",
    "validation_set['label'] = labels\n",
    "validation_set.drop(\"melanoma\", axis=1, inplace=True)\n",
    "validation_set.drop(\"seborrheic_keratosis\", axis=1, inplace=True)  \n",
    "\n",
    "labels = []\n",
    "for ix, row in test_set.iterrows():\n",
    "    if row['melanoma'] == 1.0:\n",
    "        labels.append(\"Melanoma\")\n",
    "    else:\n",
    "        labels.append(\"Non-Melanoma\")\n",
    "        \n",
    "test_set['label'] = labels\n",
    "test_set.drop(\"melanoma\", axis=1, inplace=True)\n",
    "test_set.drop(\"seborrheic_keratosis\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move the label column to the last place to match the other datasets\n",
    "cols = list(train_set_rs.columns)\n",
    "cols = cols[1:] + [cols[0]]\n",
    "train_set_rs = train_set_rs[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_rs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5476bfd",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training Data\n",
    "X_train = train_set_rs.iloc[:,:-1].reset_index(drop=True).values\n",
    "y_train = train_set_rs.iloc[:,-1].reset_index(drop=True).values\n",
    "\n",
    "# For Validation Data\n",
    "X_valid = validation_set.iloc[:,:-1].reset_index(drop=True).values\n",
    "y_valid = validation_set.iloc[:,-1].reset_index(drop=True).values\n",
    "\n",
    "# For Test Data\n",
    "X_test = test_set.iloc[:,:-1].reset_index(drop=True).values\n",
    "y_test = test_set.iloc[:,-1].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a8fd5",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde70a31",
   "metadata": {},
   "source": [
    "#### Selecting best K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a7af1",
   "metadata": {},
   "source": [
    "We will try the model on a different range of Ks to find the optimal one. Since we are interested in a precautory diagnosis for Melanoma, we would try to achieve the best recall score for the \"Melanoma\" label.<br>\n",
    "Note: $$Recall = \\frac{tp}{(tp+fn)}$$\n",
    "<br>\n",
    "Where \"tp\" is true positive and \"fn\" is false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_KNN = []\n",
    "\n",
    "# Calculating score for K values between 3 and 40\n",
    "for i in range(3, 40):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    pred_i = KNN.predict(X_valid)\n",
    "    scores_KNN.append(recall_score(y_valid, pred_i, pos_label=\"Melanoma\", average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febcac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(3, 40), scores_KNN, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='green', markersize=8)\n",
    "plt.title('Scores for K Values')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Model Score')\n",
    "#plt.savefig('./reports/figures/optimal-k-value.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = [i+3 for i, x in enumerate(scores_KNN) if x == max(scores_KNN)]\n",
    "best_k[0] # Out of all possible k neighbors that return the best recall, we want the smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aec08b",
   "metadata": {},
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=best_k[0]) # We fit the model with our optimal k number\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b33f2",
   "metadata": {},
   "source": [
    "#### Model prediction on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_KNN = KNN.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebed9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_valid, y_pred_KNN))\n",
    "print(f'Overall Model Accuracy: {accuracy_score(y_valid, y_pred_KNN):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262195c3",
   "metadata": {},
   "source": [
    "PRECISION: is the ability of a classifier not to label an instance positive that is actually negative. For each class it is defined as the ratio of true positives to the sum of true and false positives.\n",
    "\n",
    "TP – True Positives\n",
    "FP – False Positives\n",
    "\n",
    "Precision – Accuracy of positive predictions.\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "---------\n",
    "\n",
    "RECALL: is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.\n",
    "\n",
    "FN – False Negatives\n",
    "\n",
    "Recall: Fraction of positives that were correctly identified.\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "---------\n",
    "\n",
    "The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff679f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(KNN, X_valid, y_valid,\n",
    "                                 display_labels=['Melanoma', \"Non-Melanoma\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.savefig('./reports/figures/KNN-confusion-matrix-validation.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864aa3a",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e16a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeClassifier(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fbc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = DT.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_valid, y_pred_DT))\n",
    "print(f'Overall Model Accuracy: {accuracy_score(y_valid, y_pred_DT):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(DT, X_valid, y_valid,\n",
    "                                 display_labels=['Melanoma', \"Non-Melanoma\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.savefig('./reports/figures/DT-confusion-matrix-validation.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80538b65",
   "metadata": {},
   "source": [
    "Our Decision Tree model performs a little better on overall accuracy than the KNN model (69.6% vs 57.78) however it correctly identified less melanoma lesions (17% vs 54%). We decided to use the KNN model for our final test dataset as detecting melanoma is the main focus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351decd8",
   "metadata": {},
   "source": [
    "### Final run of the model on TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_predict = KNN.predict(X_test)\n",
    "print(classification_report(y_test, y_final_predict))\n",
    "print(f'Overall Model Accuracy: {accuracy_score(y_test, y_final_predict):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf053ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(KNN, X_test, y_test,\n",
    "                                 display_labels=['Melanoma', \"Non-Melanoma\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.savefig('./reports/figures/KNN-confusion-matrix-test.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4c333",
   "metadata": {},
   "source": [
    "\n",
    "Our final model trained with validation data and fitted for k=4 neighbors obtained a total accuracy of 56.58% and detected 33 our of 95 positive melanomas (35%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
