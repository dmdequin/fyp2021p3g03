{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "institutional-spider",
   "metadata": {},
   "source": [
    "# First Year Project\n",
    "## Project 3 - Effectiveness of Skin Cancer Prediction\n",
    "\n",
    "This notebook contains all of the code developed for project 3, completing tasks similar to data scientists working for a dermatologist to investigate whether some characteristics of skin lesions can be reliably measure with a smartphone app.\n",
    "\n",
    "The goal is to measure at least 2 of the following characteristics in a set of skin lesion images; asymmetry, border, and color.\n",
    "\n",
    "Then, we will try to assess how good the measurements are, by predicting the diagnosis of the skin lesions based on these features.\n",
    "\n",
    "We will focus on the **Melanoma** form of skin cancer.\n",
    "\n",
    "Group 3:<br>\n",
    "Crisanna Cornish (ccor@itu.dk)<br>\n",
    "Danielle Dequin (ddeq@itu.dk)<br>\n",
    "Gino Franco Fazzi (gifa@itu.dk)<br>\n",
    "Moneeca Abru Iftikhar Latif (abml@itu.dk)<br>\n",
    "Carl August Wismer (cwis@itu.dk)\n",
    "\n",
    "Created: 07-04-2021<br>\n",
    "Last Modified: 18-04-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-report",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-washer",
   "metadata": {},
   "source": [
    "Data was provided by the ISIC challenge data sets. <br>\n",
    "https://challenge.isic-archive.com/data\n",
    "\n",
    "Codella N, Gutman D, Celebi ME, Helba B, Marchetti MA, Dusza S, Kalloo A, Liopyris K, Mishra N, Kittler H, Halpern A. \"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)\". arXiv: 1710.05006 [cs.CV]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-material",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-comfort",
   "metadata": {},
   "source": [
    "Libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "import math\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_confusion_matrix\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-personal",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-chile",
   "metadata": {},
   "source": [
    "Constants to access data on the directory structure of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = './data/training/' \n",
    "VALID = './data/validation/'\n",
    "TEST = './data/test/'\n",
    "\n",
    "IMG = 'example_image/'\n",
    "SEG = 'example_segmentation/'\n",
    "FEAT = 'features/'\n",
    "TRUTH = 'ground_truth.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-advice",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-equity",
   "metadata": {},
   "source": [
    "Functions created for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FUNCTIONS FOR MASKED IMAGES\"\"\"\n",
    "\n",
    "def get_boundaries(image):\n",
    "    \"\"\"Function to locate the boundaries of the lesion over the whole image.\n",
    "    Takes a segmentation mask image as argument and returns the upper, lower, left and right boundaries.\"\"\"\n",
    "\n",
    "    mask = np.where(image == 1)\n",
    "    left = min(mask[1])\n",
    "    right = max(mask[1])\n",
    "    upper = min(mask[0])\n",
    "    lower = max(mask[0])\n",
    "    return upper, lower, left, right\n",
    "\n",
    "def get_center(image): # NOT NEEDED ANYMORE ?\n",
    "    \"\"\"Function that takes an image as input, and returns the centerpoint of the lesion.\"\"\"\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    center = ((up+dw)/2, (lt+rt)/2)\n",
    "    return center\n",
    "    \n",
    "def zoom(image):\n",
    "    \"\"\"Function to zoom-in (crop) the lesion from blank space. Takes a segmentation mask image as input,\n",
    "    and returns the rectangle where the lesion is found.\"\"\"\n",
    "\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    rectangle = image[up:dw+1, lt:rt+1]\n",
    "    return rectangle\n",
    "\n",
    "def cuts(image):\n",
    "    \"\"\"Function to perform a double cut (vertical and horizontal) of the lesion. Takes a segmentation mask image as input,\n",
    "    and returns the vertical and horizontal cuts (2 for each dimension). It handles uneven shapes.\"\"\"\n",
    "\n",
    "    center_h = image.shape[0] // 2 # The image shape contains a tuple with height and width (in pixels)\n",
    "    if image.shape[0] % 2 == 0: # If the height is an even number of pixels, the cut returns 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h:,:]\n",
    "    else: # If the height is an uneven number of pixels, the cut has to \"share\" the center, to return 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h+1:,:]\n",
    "        \n",
    "    center_w = image.shape[1] // 2    \n",
    "    if image.shape[1] % 2 == 0:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w:]\n",
    "    else:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w+1:]\n",
    " \n",
    "    return upside, downside, leftside, rightside\n",
    "\n",
    "\n",
    "def test_symmetry(image, rot_deg=30):\n",
    "    \"\"\"Function to test the symmetry of an image. Takes a segmentation mask image and the rotation degree interval and\n",
    "    returns a symmetry score between zero (non-symmetric) to one (completely symmetric).\"\"\"\n",
    "\n",
    "    assert (rot_deg <= 90) and (rot_deg >= 0), \"Rotation degree should be positive and at most 90 deg\"\n",
    "    optimal = 0\n",
    "    \n",
    "    for deg in range(0,91, rot_deg):\n",
    "        rot_image = skimage.transform.rotate(image, deg)\n",
    "        z = zoom(rot_image)\n",
    "        \n",
    "        upside, downside, leftside, rightside = cuts(z)\n",
    "\n",
    "        up_dw = np.sum(np.bitwise_and(upside.astype(int), np.flipud(downside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(upside.astype(int), np.flipud(downside).astype(int)))\n",
    "\n",
    "        lt_rt = np.sum(np.bitwise_and(leftside.astype(int), np.fliplr(rightside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(leftside.astype(int), np.fliplr(rightside).astype(int)))\n",
    "    \n",
    "        symmetry = (up_dw+lt_rt)/2\n",
    "        \n",
    "        if symmetry > optimal: optimal = symmetry\n",
    "\n",
    "    return symmetry\n",
    "    \n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Function to convert a RGB image to grayscale.\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def crop(image, mask, resize=True, warning=True):\n",
    "    if image.shape[:2] != mask.shape[:2]:\n",
    "        if warning:\n",
    "            print(\"Image and Mask must have the same size. OPERATION CANCELLED.\")\n",
    "        else: return\n",
    "    else:\n",
    "        img = image.copy()\n",
    "        img[mask==0] = 0\n",
    "\n",
    "        if resize:\n",
    "            u,d,l,r = get_boundaries(mask)\n",
    "            img = img[u:d,l:r,...]\n",
    "        return img\n",
    "\n",
    "def color_std(image):\n",
    "    \"\"\"A function that takes an image as input, computes and returns the average standard deviation of all the\n",
    "    rgb color values.\"\"\"\n",
    "    R = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,0]\n",
    "    G = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,1]\n",
    "    B = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,2]\n",
    "    color_std = (np.std(R) + np.std(G) + np.std(B)) /3\n",
    "    #except:\n",
    "    #    color_std = 'NA'\n",
    "    return color_std\n",
    "\n",
    "def check_border(image, border=0.01, tolerance=0.2, warning=True):\n",
    "    \"\"\"Function to check if the lesion might be exceeding the image. Take the following arguments:\n",
    "    - image: segmentation mask image to check.\n",
    "    - border: the percentage of pixels to consider as a border. 10% by default.\n",
    "    - tolerance: the percentage of tolerance for a lesion to be at the border of the image. 20% by default.\n",
    "    - warning: boolean to indicate if a textual warning should be issue when checking the border. True by default.\"\"\"\n",
    "    h = int(image.shape[0] * border)\n",
    "    w = int(image.shape[1] * border)\n",
    "    up = (np.sum(image[h,:]) / image.shape[1]) > tolerance\n",
    "    dw = (np.sum(image[-h,:]) / image.shape[1]) > tolerance\n",
    "    lt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    rt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    if warning:\n",
    "        if up or dw or lt or rt: return \"This lesion might be overflowing the image\"\n",
    "        else: return \"This lesion does not seem to be overflowing the image\"\n",
    "    else:\n",
    "        return up or dw or lt or rt\n",
    "\n",
    "\n",
    "def masker(image, sens):\n",
    "    '''Takes image, converts to a grayscale image, and returns a masked \n",
    "    image that only shows values below the sensitivity given as input.'''\n",
    "    \n",
    "    gray = rgb2gray(image) # Create grayscale image\n",
    "    img2 = gray < sens # **This level needs manually adjusting, also need to be able to automate**\n",
    "    \n",
    "    # use plt.imshow(masker(image,sens), cmap='gray') to see image\n",
    "    \n",
    "    return img2.astype(int)\n",
    "\n",
    "def dimensions(mask1):\n",
    "    '''calculates height(max) and width(90 deg to height)\n",
    "        returns height, width, rotated mask image, degree of rotation'''\n",
    "    pixels_in_col = np.max(np.sum(mask1, axis=0))\n",
    "\n",
    "    rot = 0\n",
    "    max_col = 0\n",
    "    rot_max = 0\n",
    "    for _ in range(9):\n",
    "        rot_im = transform.rotate(mask1,rot)\n",
    "        pixels_in_col = np.max(np.sum(rot_im, axis=0))\n",
    "        if pixels_in_col > max_col:\n",
    "            max_col = pixels_in_col\n",
    "            rot_max = rot\n",
    "            pixels_in_row = np.max(np.sum(rot_im, axis=1))\n",
    "        rot += 10\n",
    "\n",
    "    return max_col, pixels_in_row, rot_max\n",
    "\n",
    "def measure_area_perimeter(mask):\n",
    "    \"\"\"A function that takes either a segmented image or perimeter \n",
    "    image as input, and calculates the length of the perimeter of a lesion.\"\"\"\n",
    "    \n",
    "    # Measure area: the sum of all white pixels in the mask image\n",
    "    area = np.sum(mask)\n",
    "\n",
    "    # Measure perimeter: first find which pixels belong to the perimeter.\n",
    "    perimeter = measure.perimeter(mask)\n",
    "    \n",
    "    return area, perimeter\n",
    "\n",
    "def predict(bi_image): # Predict might be a little confusing ?\n",
    "    \n",
    "    area = np.sum(bi_image)\n",
    "    _, peri = perimeter(bi_image)\n",
    "    \n",
    "    area_from_peri = pi*((peri/(2*pi))**2)\n",
    "    peri_from_area = 2*pi*sqrt(area/pi)\n",
    "    \n",
    "    return area, area_from_peri, peri, peri_from_area  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-terrorism",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-clarity",
   "metadata": {},
   "source": [
    "(NOTE) We load and access the metadata included in our source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {} # A main dictionary will hold our different labels datasets\n",
    "\n",
    "df['train'] = {'path': TRAIN, 'label': pd.read_csv(TRAIN + TRUTH, index_col='image_id')}\n",
    "df['validation'] = {'path': VALID, 'label': pd.read_csv(VALID + TRUTH, index_col='image_id')}\n",
    "df['test'] = {'path': TEST, 'label': pd.read_csv(TEST + TRUTH, index_col='image_id')}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-thermal",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-thursday",
   "metadata": {},
   "source": [
    "(NOTE) Here is shown how we visualize and mask the images to get familiar with the images and their attributes. The lesion images present in the dataset have been cropped and masked using the crop function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-demonstration",
   "metadata": {},
   "source": [
    "### Load Image and Segmentation Image Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = 'ISIC_0000000'\n",
    "image = plt.imread(df['train']['path']+IMG+IM+'.jpg')\n",
    "seg = plt.imread(df['train']['path']+SEG+IM+'_segmentation.png')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7, 5))\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(seg, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-village",
   "metadata": {},
   "source": [
    "### Showing how the zoom function works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-integer",
   "metadata": {},
   "source": [
    "This shows how the image was cropped so that the border is cut to the edges of the lesion, resulting in the cropped image of the lesion seen above on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(zoom(seg), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-longer",
   "metadata": {},
   "source": [
    "### Convert an image to grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-princess",
   "metadata": {},
   "source": [
    "This shows how the rgb2gray function works to convert an image to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb2gray(image), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-system",
   "metadata": {},
   "source": [
    "### VIsualize the masker function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-hollow",
   "metadata": {},
   "source": [
    "This function was written to create our own segmentation images. When the image has been masked with a segmentation image already, the function outputs differently. Since the images in this repository have all already been masked, it is not as clear to see how this functino would work. In addition, since we already had access to segmentation images, we did not further explore optimization of this technique for large amounts of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masker(image,140), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-novelty",
   "metadata": {},
   "source": [
    "### Visualize output of function for Area and Perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-tongue",
   "metadata": {},
   "source": [
    "This shows the output of the function that shows area and perimeter of a lesion, as well as a visual display of the perimeter of the lesion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "area, perimeter = measure_area_perimeter(seg)\n",
    "print(f'Area: {area}\\nPerimeter: {perimeter}')\n",
    "\n",
    "struct_el = morphology.disk(1)\n",
    "mask_eroded = morphology.binary_erosion(seg, struct_el)\n",
    "image_perimeter = seg - mask_eroded\n",
    "plt.imshow(image_perimeter, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-evans",
   "metadata": {},
   "source": [
    "### Output of the cuts function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-saturn",
   "metadata": {},
   "source": [
    "The output of this function is then used in the test_symmetry function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,d,l,r = cuts(seg)\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(5,3), dpi=350)\n",
    "ax1.imshow(u, cmap='gray')\n",
    "ax2.imshow(d, cmap='gray')\n",
    "ax3.imshow(l, cmap='gray')\n",
    "ax4.imshow(r, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-malta",
   "metadata": {},
   "source": [
    "### Result of the test_symmetry function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_symmetry(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-acrobat",
   "metadata": {},
   "source": [
    "This lesion shows a 76.65% symmetry, which lines up well with the visual symmetry of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-density",
   "metadata": {},
   "source": [
    "# Dataset Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-biotechnology",
   "metadata": {},
   "source": [
    "#### Figure compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-latex",
   "metadata": {},
   "source": [
    "In order to work more efficiently, we decide to crop the images to reduce their dimensions to the part of the image that contains the lesion. For this, we will use our segmented masks, as following: the color images will be croped to the rectangle where the lesion is, and saving the new image with reduced dimensions. This process must be done only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    i = 1\n",
    "    for k, v in df.items():\n",
    "        for img_id in v['label'].index:\n",
    "            imgpath = v['path'] + IMG + img_id + '.jpg'\n",
    "            mskpath = v['path'] + SEG + img_id + '_segmentation.png'\n",
    "            img = plt.imread(imgpath)\n",
    "            msk = plt.imread(mskpath)\n",
    "            new = crop(img, msk, warning=False)\n",
    "            if new is None:\n",
    "                pass\n",
    "            else: plt.imsave(imgpath, new)\n",
    "            print(f'\\rResizing image # {i}', end='\\r')\n",
    "            i += 1\n",
    "            \n",
    "else: print(\"OPERATION CANCELLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-contract",
   "metadata": {},
   "source": [
    "### We check for lesions overflowing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    with open('./to_check.csv', 'w') as outfile:\n",
    "        outfile.write('image_id'+','+'from Dataset'+'\\n')\n",
    "        for k, data in df.items():\n",
    "                for img_id in data['label'].index:\n",
    "                    img = plt.imread(data['path'] + SEG + img_id + '_segmentation.png') \n",
    "                    if check_border(img, warning=False) == True:\n",
    "                        outfile.write(img_id+','+data['path']+'\\n')\n",
    "else:\n",
    "    print(\"OPERATION CANCELLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-syndication",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-criminal",
   "metadata": {},
   "source": [
    "(NOTE) We proceed to extract features of interest for our predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-validity",
   "metadata": {},
   "source": [
    "#### Asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-affiliate",
   "metadata": {},
   "source": [
    "To test for asymmetry we run a function to calculate a score based on how similar an image is when cut horizontally and vertically. We assign a score between 0 (non asymmetric) and 1 (totally asymmetric) for both cuts, and we take the average to convey a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a test on a black circle, where it's symmetry should be close to 1\n",
    "test_circle = plt.imread('./data/test-black-circle.png') # Load the circle test\n",
    "test_circle = test_circle[:,:,0]\n",
    "print(f'Symmetry test for black circle: {test_symmetry(circle):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /symmetry.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        symmetry = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating symmetry: {ptg:.2%}', end='\\r')\n",
    "            symmetry[ix] = test_symmetry(image)\n",
    "            i += 1\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'symmetry_{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'symmetry'+'\\n')\n",
    "            for k, v in symmetry.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-homeless",
   "metadata": {},
   "source": [
    "#### Border (Compactness method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-tsunami",
   "metadata": {},
   "source": [
    "To test for border smoothness we use the compactness method. Compactness is defined as the ratio of the\n",
    "area of an object to the area of a circle with the same perimeter.\n",
    "The measure takes a maximum value of 1 for a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a test on a black circle, where it's compactness should be close to 1\n",
    "circle_area, circle_perimeter = measure_area_perimeter(test_circle)\n",
    "circle_compactness = (4* math.pi * circle_area) / (circle_perimeter**2)\n",
    "print(f'Compactness test for black circle: {circle_compactness:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /compactness.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        compactness = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating compactness: {ptg:.2%}', end='\\r')\n",
    "            area, per = measure_area_perimeter(image)\n",
    "            compactness[ix] = (4* math.pi * area) / (per**2)\n",
    "            i += 1\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'compactness_{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'compactness'+'\\n')\n",
    "            for k, v in compactness.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-coast",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-knight",
   "metadata": {},
   "source": [
    "In order to evaluate the difference in lesion colors, we take the standard deviation for each of the 3 RGB channels of the cropped image (to reduce noise), and then we average the 3 deviations to obtain a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /color_deviation.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        color_deviation = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + IMG + str(ix) + \".jpg\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating color deviation: {ptg:.2%}', end='\\r') \n",
    "            color_deviation[ix] = color_std(image)\n",
    "            i += 1\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'color_deviation{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'color_deviation'+'\\n')\n",
    "            for k, v in color_deviation.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-relation",
   "metadata": {},
   "source": [
    "### Aggregating features to datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-present",
   "metadata": {},
   "source": [
    "We will now add the recently extracted features to our main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['symmetry', 'compactness', 'color_deviation']\n",
    "for dataset in df.keys():\n",
    "    for feat in feat_list:\n",
    "        symmetry = pd.read_csv(df[dataset]['path'] + FEAT + 'symmetry.csv', index_col='image_id') \n",
    "        compactness = pd.read_csv(df[dataset]['path'] + FEAT + 'compactness.csv', index_col='image_id')\n",
    "        color_deviation = pd.read_csv(df[dataset]['path'] + FEAT + 'color_deviation.csv', index_col='image_id')\n",
    "        df[dataset]['features'] = symmetry.merge(compactness, how = 'inner', on = 'image_id')\\\n",
    "        .merge(color_deviation, how = 'inner', on = 'image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train']['features'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-lebanon",
   "metadata": {},
   "source": [
    "### Analysis of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df['train']['label'].merge(df['train']['features'], how = 'inner', on = 'image_id')\n",
    "train_set.drop('seborrheic_keratosis', axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.loc[train_set.melanoma == 1, 'melanoma'] = \"Melanoma\"\n",
    "train_set.loc[train_set.melanoma == 0, 'melanoma'] = \"Non-Melanoma\"\n",
    "train_set.columns = ['label'] + list(train_set.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2, figsize=(15,12), dpi=350)\n",
    "\n",
    "i = 0\n",
    "for f1 in feat_list:\n",
    "    for f2 in feat_list:\n",
    "        if f1 != f2:\n",
    "            if i < 3:\n",
    "                axis = (i, 0)\n",
    "            else:\n",
    "                axis = (i-3, 1)\n",
    "            ax[0,0] = sns.scatterplot(x=f1, y=f2, data=train_set, hue='label', ax=ax[axis])\n",
    "            i += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = train_set.loc[train_set.label == \"Melanoma\"]\n",
    "negative = train_set.loc[train_set.label == \"Non-Melanoma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=250)\n",
    "\n",
    "sns.kdeplot(x = 'symmetry', data=positive, cumulative= False, shade=True, clip=(0,1), color='r')\n",
    "sns.kdeplot(x = 'symmetry', data=negative, cumulative= False, shade=True, clip=(0,1), color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=250)\n",
    "\n",
    "sns.kdeplot(x = 'compactness', data=positive, cumulative= False, shade=True, clip=(0,1), color='r')\n",
    "sns.kdeplot(x = 'compactness', data=negative, cumulative= False, shade=True, clip=(0,1), color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=250)\n",
    "\n",
    "sns.kdeplot(x = 'color_deviation', data=positive, cumulative= False, shade=True, color='r')\n",
    "sns.kdeplot(x = 'color_deviation', data=negative, cumulative= False, shade=True, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-subject",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-universe",
   "metadata": {},
   "source": [
    "We first create the set with features and labels for validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Validation Data\n",
    "validation_set = df['validation']['label'].merge(df['validation']['features'],\\\n",
    "                                                 how = 'inner', on = 'image_id')\n",
    "validation_set.drop('seborrheic_keratosis', axis= 1, inplace=True)\n",
    "\n",
    "# For Test Data\n",
    "test_set = df['test']['label'].merge(df['test']['features'], how = 'inner', on = 'image_id')\n",
    "test_set.drop('seborrheic_keratosis', axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Validation Data\n",
    "validation_set.loc[validation_set.melanoma == 1, 'melanoma'] = \"Melanoma\"\n",
    "validation_set.loc[validation_set.melanoma == 0, 'melanoma'] = \"Non-Melanoma\"\n",
    "validation_set.columns = ['label'] + list(validation_set.columns)[1:]\n",
    "\n",
    "# For Test Data\n",
    "test_set.loc[test_set.melanoma == 1, 'melanoma'] = \"Melanoma\"\n",
    "test_set.loc[test_set.melanoma == 0, 'melanoma'] = \"Non-Melanoma\"\n",
    "test_set.columns = ['label'] + list(test_set.columns)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-chuck",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training Data\n",
    "X_train = train_set.iloc[:,1:].reset_index(drop=True).values\n",
    "y_train = train_set.iloc[:,0].reset_index(drop=True).values\n",
    "\n",
    "# For Validation Data\n",
    "X_valid = validation_set.iloc[:,1:].reset_index(drop=True).values\n",
    "y_valid = validation_set.iloc[:,0].reset_index(drop=True).values\n",
    "\n",
    "# For Test Data\n",
    "X_test = test_set.iloc[:,1:].reset_index(drop=True).values\n",
    "y_test = test_set.iloc[:,0].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-willow",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# For Validation Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_valid)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "\n",
    "# For Test Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-toolbox",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-browse",
   "metadata": {},
   "source": [
    "#### Selecting best K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-sewing",
   "metadata": {},
   "source": [
    "We will try the model on a different range of Ks to find the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_KNN = []\n",
    "\n",
    "# Calculating score for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    pred_i = KNN.predict(X_valid)\n",
    "    scores_KNN.append(accuracy_score(y_valid, pred_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), scores_KNN, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='green', markersize=8)\n",
    "plt.title('Scores for K Values')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Model Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = [i for i, x in enumerate(scores) if x == max(scores)]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-ratio",
   "metadata": {},
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=6)\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-chile",
   "metadata": {},
   "source": [
    "#### Model prediction on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_KNN = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_KNN))\n",
    "print(f'Overall Model Accuracy: {accuracy_score(y_test, y_pred_KNN):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(KNN, X_test, y_test,\n",
    "                                 display_labels=['Melanoma', 'Non-Melanoma'],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-orientation",
   "metadata": {},
   "source": [
    "PRECISION: is the ability of a classifier not to label an instance positive that is actually negative. For each class it is defined as the ratio of true positives to the sum of true and false positives.\n",
    "\n",
    "TP – True Positives\n",
    "FP – False Positives\n",
    "\n",
    "Precision – Accuracy of positive predictions.\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "Our model achieved a precision of 0.16 for Melanoma and 0.80 for Non-Melanoma, with a joint accuracy of 73.50 %.\n",
    "\n",
    "---------\n",
    "\n",
    "RECALL: is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.\n",
    "\n",
    "FN – False Negatives\n",
    "\n",
    "Recall: Fraction of positives that were correctly identified.\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "Our model did not perform specially well on predicting Melanoma instances.\n",
    "\n",
    "---------\n",
    "\n",
    "The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-lyric",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeClassifier(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_DT))\n",
    "print(f'Overall Model Accuracy: {accuracy_score(y_test, y_pred_DT):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(DT, X_test, y_test,\n",
    "                                 display_labels=['Melanoma', 'Non-Melanoma'],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-light",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
