{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "institutional-spider",
   "metadata": {},
   "source": [
    "# First Year Project - ITU CPH\n",
    "\n",
    "## Project 3 - Effectiveness of Skin Cancer Prediction\n",
    "\n",
    "This notebook contains all of the code developed for project 3, completing tasks similar to data scientists working for a dermatologist to investigate whether some characteristics of skin lesions can be reliably measure with a smartphone app.\n",
    "\n",
    "The goal is to measure at least 2 of the following characteristics in a set of skin lesion images; asymmetry, border, and color.\n",
    "\n",
    "Then, we will try to assess how good the measurements are, by predicting the diagnosis of the skin lesions based on these features.\n",
    "\n",
    "We will focus on the **Melanoma** form of skin cancer.\n",
    "\n",
    "Group 3:<br>\n",
    "Crisanna Cornish (ccor@itu.dk)<br>\n",
    "Danielle Dequin (ddeq@itu.dk)<br>\n",
    "Gino Franco Fazzi (gifa@itu.dk)<br>\n",
    "Moneeca Abru Iftikhar Latif (abml@itu.dk)<br>\n",
    "Carl August Wismer (cwis@itu.dk)\n",
    "\n",
    "Created: 07-04-2021<br>\n",
    "Last Modified: 15-04-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-bradley",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-vitamin",
   "metadata": {},
   "source": [
    "Data was provided by the ISIC challenge data sets. <br>\n",
    "https://challenge.isic-archive.com/data\n",
    "\n",
    "Codella N, Gutman D, Celebi ME, Helba B, Marchetti MA, Dusza S, Kalloo A, Liopyris K, Mishra N, Kittler H, Halpern A. \"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)\". arXiv: 1710.05006 [cs.CV]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-material",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-comfort",
   "metadata": {},
   "source": [
    "Libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "\n",
    "from skimage import morphology\n",
    "from skimage.morphology import opening\n",
    "\n",
    "from skimage import measure\n",
    "from skimage import transform\n",
    "from skimage.transform import rotate\n",
    "from skimage import filters\n",
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import disk_level_set\n",
    "\n",
    "import math\n",
    "from math import pi\n",
    "from math import sqrt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-personal",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-chile",
   "metadata": {},
   "source": [
    "Constants to access data on the directory structure of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = './data/example_image/'\n",
    "SEG_PATH = './data/example_segmentation/'\n",
    "FEAT_PATH = './features/'\n",
    "\n",
    "TRUTH = './data/ISIC-2017_Training_Part3_GroundTruth.csv'\n",
    "FEATURES = '/features/features.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-advice",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-equity",
   "metadata": {},
   "source": [
    "Functions created for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FUNCTIONS FOR MASKED IMAGES\"\"\"\n",
    "\n",
    "def get_boundaries(image):\n",
    "    \"\"\"Function to locate the boundaries of the lesion over the whole image.\n",
    "    Takes a segmentation mask image as argument and returns the upper, lower, left and right boundaries.\"\"\"\n",
    "\n",
    "    mask = np.where(image == 1)\n",
    "    left = min(mask[1])\n",
    "    right = max(mask[1])\n",
    "    upper = min(mask[0])\n",
    "    lower = max(mask[0])\n",
    "    return upper, lower, left, right\n",
    "\n",
    "def get_center(image): # NOT NEEDED ANYMORE ?\n",
    "    \"\"\"Function that takes an image as input, and returns the centerpoint of the lesion.\"\"\"\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    center = ((up+dw)/2, (lt+rt)/2)\n",
    "    return center\n",
    "    \n",
    "def zoom(image):\n",
    "    \"\"\"Function to zoom-in (crop) the lesion from blank space. Takes a segmentation mask image as input,\n",
    "    and returns the rectangle where the lesion is found.\"\"\"\n",
    "\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    rectangle = image[up:dw+1, lt:rt+1]\n",
    "    return rectangle\n",
    "\n",
    "def cuts(image):\n",
    "    \"\"\"Function to perform a double cut (vertical and horizontal) of the lesion. Takes a segmentation mask image as input,\n",
    "    and returns the vertical and horizontal cuts (2 for each dimension). It handles uneven shapes.\"\"\"\n",
    "\n",
    "    center_h = image.shape[0] // 2 # The image shape contains a tuple with height and width (in pixels)\n",
    "    if image.shape[0] % 2 == 0: # If the height is an even number of pixels, the cut returns 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h:,:]\n",
    "    else: # If the height is an uneven number of pixels, the cut has to \"share\" the center, to return 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h+1:,:]\n",
    "        \n",
    "    center_w = image.shape[1] // 2    \n",
    "    if image.shape[1] % 2 == 0:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w:]\n",
    "    else:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w+1:]\n",
    " \n",
    "    return upside, downside, leftside, rightside\n",
    "\n",
    "\n",
    "def test_symmetry(image, rot_deg=30):\n",
    "    \"\"\"Function to test the symmetry of an image. Takes a segmentation mask image and the rotation degree interval and\n",
    "    returns a symmetry score between zero (non-symmetric) to one (completely symmetric).\"\"\"\n",
    "\n",
    "    assert (rot_deg <= 90) and (rot_deg >= 0), \"Rotation degree should be positive and at most 90 deg\"\n",
    "    optimal = 0\n",
    "    \n",
    "    for deg in range(0,91, rot_deg):\n",
    "        rot_image = skimage.transform.rotate(image, deg)\n",
    "        z = zoom(rot_image)\n",
    "        \n",
    "        upside, downside, leftside, rightside = cuts(z)\n",
    "\n",
    "        up_dw = np.sum(np.bitwise_and(upside.astype(int), np.flipud(downside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(upside.astype(int), np.flipud(downside).astype(int)))\n",
    "\n",
    "        lt_rt = np.sum(np.bitwise_and(leftside.astype(int), np.fliplr(rightside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(leftside.astype(int), np.fliplr(rightside).astype(int)))\n",
    "    \n",
    "        symmetry = (up_dw+lt_rt)/2\n",
    "        \n",
    "        if symmetry > optimal: optimal = symmetry\n",
    "\n",
    "    return symmetry\n",
    "    \n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Function to convert a RGB image to grayscale.\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def crop(image, mask):\n",
    "    \"\"\"\"\"\"\n",
    "    img = image.copy()\n",
    "    img[mask==0] = 0\n",
    "    return img\n",
    "\n",
    "def color_std(image):\n",
    "    \"\"\"A function that takes an image as input, computes and returns the average standard deviation of all the\n",
    "    rgb color values.\"\"\"\n",
    "    try:\n",
    "        R = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,0]\n",
    "        G = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,1]\n",
    "        B = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,2]\n",
    "        color_std = (np.std(R) + np.std(G) + np.std(B)) /3\n",
    "    except:\n",
    "        color_std = 'NA'\n",
    "    return color_std\n",
    "\n",
    "def check_border(image, border=0.01, tolerance=0.2, warning=True):\n",
    "    \"\"\"Function to check if the lesion might be exceeding the image. Take the following arguments:\n",
    "    - image: segmentation mask image to check.\n",
    "    - border: the percentage of pixels to consider as a border. 10% by default.\n",
    "    - tolerance: the percentage of tolerance for a lesion to be at the border of the image. 20% by default.\n",
    "    - warning: boolean to indicate if a textual warning should be issue when checking the border. True by default.\"\"\"\n",
    "    h = int(image.shape[0] * border)\n",
    "    w = int(image.shape[1] * border)\n",
    "    up = (np.sum(image[h,:]) / image.shape[1]) > tolerance\n",
    "    dw = (np.sum(image[-h,:]) / image.shape[1]) > tolerance\n",
    "    lt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    rt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    if warning:\n",
    "        if up or dw or lt or rt: return \"This lesion might be overflowing the image\"\n",
    "        else: return \"This lesion does not seem to be overflowing the image\"\n",
    "    else:\n",
    "        return up or dw or lt or rt\n",
    "    \n",
    "\"\"\"\n",
    "#def laydown(image): # I THINK WE MAY NOT NEED THIS\n",
    "#    z = zoom(image)\n",
    "#    u, d, l, r = get_boundaries(z)\n",
    "#    if (d-u) >= (r-l):\n",
    "#        return skimage.transform.rotate(image, 90) \n",
    "#    else: return image\n",
    "        \n",
    "def reverse(image):\n",
    "    new = image.copy()\n",
    "    new[np.where(image == 1)], new[np.where(image == 0)] = 0, 1\n",
    "    return new\n",
    "\"\"\"\n",
    "def masker(image, sens):\n",
    "    '''Takes image, converts to a grayscale image, and returns a masked \n",
    "    image that only shows values below the sensitivity given as input.'''\n",
    "    \n",
    "    gray = rgb2gray(image) # Create grayscale image\n",
    "    img2 = gray < sens # **This level needs manually adjusting, also need to be able to automate**\n",
    "    \n",
    "    # use plt.imshow(masker(image,sens), cmap='gray') to see image\n",
    "    \n",
    "    return img2.astype(int)\n",
    "\n",
    "def dimensions(mask1):\n",
    "    '''calculates height(max) and width(90 deg to height)\n",
    "        returns height, width, rotated mask image, degree of rotation'''\n",
    "    pixels_in_col = np.max(np.sum(mask1, axis=0))\n",
    "\n",
    "    rot = 0\n",
    "    max_col = 0\n",
    "    rot_max = 0\n",
    "    for _ in range(9):\n",
    "        rot_im = transform.rotate(mask1,rot)\n",
    "        pixels_in_col = np.max(np.sum(rot_im, axis=0))\n",
    "        if pixels_in_col > max_col:\n",
    "            max_col = pixels_in_col\n",
    "            rot_max = rot\n",
    "            pixels_in_row = np.max(np.sum(rot_im, axis=1))\n",
    "        rot += 10\n",
    "\n",
    "    return max_col, pixels_in_row, rot_max\n",
    "\n",
    "def measure_area_perimeter(mask, option=1):\n",
    "    \"\"\"A function that takes either a segmented image or perimeter \n",
    "    image as input, and calculates the length of the perimeter of a lesion.\"\"\"\n",
    "    \n",
    "    # Measure area: the sum of all white pixels in the mask image\n",
    "    area = np.sum(mask)\n",
    "\n",
    "    # Measure perimeter: first find which pixels belong to the perimeter.\n",
    "    if option == 1:\n",
    "        struct_el = morphology.disk(1)\n",
    "        mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "        image_perimeter = mask - mask_eroded\n",
    "\n",
    "        # Now we have the perimeter image, the sum of all white pixels in it\n",
    "        perimeter = np.sum(image_perimeter)\n",
    "    else:\n",
    "        perimeter = measure.perimeter(mask)\n",
    "\n",
    "    return area, perimeter\n",
    "\n",
    "def predict(bi_image):\n",
    "    \"\"\"\"\"\"\n",
    "    area = np.sum(bi_image)\n",
    "    _, peri = perimeter(bi_image)\n",
    "    \n",
    "    area_from_peri = pi*((peri/(2*pi))**2)\n",
    "    peri_from_area = 2*pi*sqrt(area/pi)\n",
    "    \n",
    "    return area, area_from_peri, peri, peri_from_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-thermal",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-thursday",
   "metadata": {},
   "source": [
    "Here we visualize a couple of images and masks to get familiar with the images and its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-night",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "geographic-terrorism",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-clarity",
   "metadata": {},
   "source": [
    "(NOTE) We load and access the metadata included in our source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRUTH, index_col='image_id')\n",
    "df = df.astype(int) # Transform to int\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-earthquake",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d180a9c45b9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'non-cancer'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Define a 'non-cancer' label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['non-cancer'] = 1 - df.sum(axis=1) # Define a 'non-cancer' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "complete-syndication",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-criminal",
   "metadata": {},
   "source": [
    "(NOTE) We proceed to extract features of interest for our predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-validity",
   "metadata": {},
   "source": [
    "#### Asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-affiliate",
   "metadata": {},
   "source": [
    "To test for asymmetry we run a function to calculate a score based on how similar an image is when cut horizontally and vertically. We assign a score between 0 (non asymmetric) and 1 (totally asymmetric) for both cuts, and we take the average to convey a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "REWRITE = input(\"Do you wish to overwrite the /features/symmetry.csv file?: (Yes/No) \")\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    symmetry = {}\n",
    "    i = 1\n",
    "    for ix, row in df[:10].iterrows():\n",
    "        file_path = SEG_PATH + str(ix) + \"_segmentation.png\"\n",
    "        image = plt.imread(file_path)\n",
    "        \n",
    "        ptg = round((i / 10) * 100,2)\n",
    "        print(f'\\rCalculating symmetry: {ptg}%', end='\\r')\n",
    "        symmetry[ix] = test_symmetry(image)\n",
    "        i += 1\n",
    "else: print(\"OPERATION CANCELLED\")\n",
    "    \n",
    "if REWRITE.lower().startswith(\"y\"):\n",
    "    with open(FEAT_PATH + 'symmetry.csv', 'w') as outfile:\n",
    "        outfile.write('image_id'+','+'symmetry'+'\\n')\n",
    "        for k, v in symmetry.items():\n",
    "            line = k +','+str(v)\n",
    "            outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-homeless",
   "metadata": {},
   "source": [
    "#### Border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "express-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This operation may take several minutes. Do you wish to continue: (Yes/No) n\n",
      "Do you wish to overwrite the /features/compactness.csv file?: (Yes/No) n\n",
      "\n",
      "----- PLEASE BE PATIENT -----\n",
      "\n",
      "OPERATION CANCELLED\n"
     ]
    }
   ],
   "source": [
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "REWRITE = input(\"Do you wish to overwrite the /features/compactness.csv file?: (Yes/No) \")\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    compactness = {}\n",
    "    i = 1\n",
    "    for ix, row in df.iterrows():\n",
    "        file_path = SEG_PATH + str(ix) + \"_segmentation.png\"\n",
    "        image = plt.imread(file_path)\n",
    "        \n",
    "        ptg = round(i / len(df.index)*100,2)\n",
    "        print(f'\\rCalculating compactness: {ptg}%', end='\\r')\n",
    "        area, per = measure_area_perimeter(image, option=2)\n",
    "        compactness[ix] = (4* math.pi * area) / (per**2)\n",
    "        i += 1\n",
    "else: print(\"OPERATION CANCELLED\")\n",
    "    \n",
    "if REWRITE.lower().startswith(\"y\"):\n",
    "    with open(FEAT_PATH + 'compactness.csv', 'w') as outfile:\n",
    "        outfile.write('image_id'+','+'compactness'+'\\n')\n",
    "        for k, v in compactness.items():\n",
    "            line = k +','+str(v)\n",
    "            outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = np.ones([4,4])\n",
    "print(measure_area_perimeter(test, option=2))\n",
    "lt = np.where(rect == 1)\n",
    "#print(list(lt[0])+list(lt[1]))\n",
    "x= len(set(list(lt[0]) + list(lt[1])))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(set(lt)) + len(set(lt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-paper",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-occupation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alike-subject",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-microwave",
   "metadata": {},
   "source": [
    "#### Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-chuck",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-atlas",
   "metadata": {},
   "source": [
    "#### Feature scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-ratio",
   "metadata": {},
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-chile",
   "metadata": {},
   "source": [
    "#### Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-browse",
   "metadata": {},
   "source": [
    "#### Model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
