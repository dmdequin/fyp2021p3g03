{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "institutional-spider",
   "metadata": {},
   "source": [
    "# First Year Project\n",
    "## Project 3 - Effectiveness of Skin Cancer Prediction\n",
    "\n",
    "This notebook contains all of the code developed for project 3, completing tasks similar to data scientists working for a dermatologist to investigate whether some characteristics of skin lesions can be reliably measure with a smartphone app.\n",
    "\n",
    "The goal is to measure at least 2 of the following characteristics in a set of skin lesion images; asymmetry, border, and color.\n",
    "\n",
    "Then, we will try to assess how good the measurements are, by predicting the diagnosis of the skin lesions based on these features.\n",
    "\n",
    "We will focus on the **Melanoma** form of skin cancer.\n",
    "\n",
    "Group 3:<br>\n",
    "Crisanna Cornish (ccor@itu.dk)<br>\n",
    "Danielle Dequin (ddeq@itu.dk)<br>\n",
    "Gino Franco Fazzi (gifa@itu.dk)<br>\n",
    "Moneeca Abru Iftikhar Latif (abml@itu.dk)<br>\n",
    "Carl August Wismer (cwis@itu.dk)\n",
    "\n",
    "Created: 07-04-2021<br>\n",
    "Last Modified: 18-04-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-report",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-washer",
   "metadata": {},
   "source": [
    "Data was provided by the ISIC challenge data sets. <br>\n",
    "https://challenge.isic-archive.com/data\n",
    "\n",
    "Codella N, Gutman D, Celebi ME, Helba B, Marchetti MA, Dusza S, Kalloo A, Liopyris K, Mishra N, Kittler H, Halpern A. \"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)\". arXiv: 1710.05006 [cs.CV]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-material",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-comfort",
   "metadata": {},
   "source": [
    "Libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "import math\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,\\\n",
    "confusion_matrix, accuracy_score, plot_confusion_matrix, recall_score\n",
    "from sklearn import tree\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-personal",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-chile",
   "metadata": {},
   "source": [
    "Constants to access data on the directory structure of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = './data/training/' \n",
    "VALID = './data/validation/'\n",
    "TEST = './data/test/'\n",
    "\n",
    "IMG = 'example_image/'\n",
    "SEG = 'example_segmentation/'\n",
    "FEAT = 'features/'\n",
    "TRUTH = 'ground_truth.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-advice",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-equity",
   "metadata": {},
   "source": [
    "Functions created for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FUNCTIONS FOR MASKED IMAGES\"\"\"\n",
    "\n",
    "def get_boundaries(image):\n",
    "    \"\"\"Function to locate the boundaries of the lesion over the whole image.\n",
    "    Takes a segmentation mask image as argument and returns the upper, lower, left and right boundaries.\"\"\"\n",
    "\n",
    "    mask = np.where(image == 1)\n",
    "    left = min(mask[1])\n",
    "    right = max(mask[1])\n",
    "    upper = min(mask[0])\n",
    "    lower = max(mask[0])\n",
    "    return upper, lower, left, right\n",
    "\n",
    "def get_center(image): # NOT NEEDED ANYMORE ?\n",
    "    \"\"\"Function that takes an image as input, and returns the centerpoint of the lesion.\"\"\"\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    center = ((up+dw)/2, (lt+rt)/2)\n",
    "    return center\n",
    "    \n",
    "def zoom(image):\n",
    "    \"\"\"Function to zoom-in (crop) the lesion from blank space. Takes a segmentation mask image as input,\n",
    "    and returns the rectangle where the lesion is found.\"\"\"\n",
    "\n",
    "    up, dw, lt, rt = get_boundaries(image)\n",
    "    rectangle = image[up:dw+1, lt:rt+1]\n",
    "    return rectangle\n",
    "\n",
    "def cuts(image):\n",
    "    \"\"\"Function to perform a double cut (vertical and horizontal) of the lesion. Takes a segmentation mask image as input,\n",
    "    and returns the vertical and horizontal cuts (2 for each dimension). It handles uneven shapes.\"\"\"\n",
    "\n",
    "    center_h = image.shape[0] // 2 # The image shape contains a tuple with height and width (in pixels)\n",
    "    if image.shape[0] % 2 == 0: # If the height is an even number of pixels, the cut returns 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h:,:]\n",
    "    else: # If the height is an uneven number of pixels, the cut has to \"share\" the center, to return 2 equal sides\n",
    "        upside = image[:center_h,:]\n",
    "        downside = image[center_h+1:,:]\n",
    "        \n",
    "    center_w = image.shape[1] // 2    \n",
    "    if image.shape[1] % 2 == 0:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w:]\n",
    "    else:\n",
    "        leftside = image[:,:center_w]\n",
    "        rightside = image[:,center_w+1:]\n",
    "    return upside, downside, leftside, rightside\n",
    "\n",
    "\n",
    "def test_symmetry(image, rot_deg=5):\n",
    "    \"\"\"Function to test the symmetry of an image. Takes a segmentation mask image and the rotation degree interval and\n",
    "    returns a symmetry score between zero (non-symmetric) to one (completely symmetric).\"\"\"\n",
    "\n",
    "    assert (rot_deg <= 90) and (rot_deg >= 0), \"Rotation degree should be positive and at most 90 deg\"\n",
    "    optimal = 0\n",
    "    \n",
    "    for deg in range(0,91, rot_deg):\n",
    "        rot_image = skimage.transform.rotate(image, deg, resize=True)\n",
    "        z = zoom(rot_image)\n",
    "        \n",
    "        upside, downside, leftside, rightside = cuts(z)\n",
    "\n",
    "        up_dw = np.sum(np.bitwise_and(upside.astype(int), np.flipud(downside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(upside.astype(int), np.flipud(downside).astype(int)))\n",
    "\n",
    "        lt_rt = np.sum(np.bitwise_and(leftside.astype(int), np.fliplr(rightside).astype(int))) /\\\n",
    "        np.sum(np.bitwise_or(leftside.astype(int), np.fliplr(rightside).astype(int)))\n",
    "    \n",
    "        symmetry = (up_dw+lt_rt)/2\n",
    "        \n",
    "        if symmetry > optimal: optimal = symmetry\n",
    "\n",
    "    return symmetry\n",
    "    \n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Function to convert a RGB image to grayscale.\"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def crop(image, mask, resize=True, warning=True):\n",
    "    if image.shape[:2] != mask.shape[:2]:\n",
    "        if warning:\n",
    "            print(\"Image and Mask must have the same size. OPERATION CANCELLED.\")\n",
    "        else: return\n",
    "    else:\n",
    "        img = image.copy()\n",
    "        img[mask==0] = 0\n",
    "\n",
    "        if resize:\n",
    "            u,d,l,r = get_boundaries(mask)\n",
    "            img = img[u:d,l:r,...]\n",
    "        return img\n",
    "\n",
    "def color_std(image):\n",
    "    \"\"\"A function that takes an image as input, computes and returns the average standard deviation of all the\n",
    "    rgb color values.\"\"\"\n",
    "    R = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,0]\n",
    "    G = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,1]\n",
    "    B = image[np.where(image[:,:,0] != 0) and np.where(image[:,:,1] != 0) and np.where(image[:,:,2] != 0)][:,2]\n",
    "    color_std = (np.std(R) + np.std(G) + np.std(B)) /3\n",
    "    #except:\n",
    "    #    color_std = 'NA'\n",
    "    return color_std\n",
    "\n",
    "def check_border(image, border=0.01, tolerance=0.2, warning=True):\n",
    "    \"\"\"Function to check if the lesion might be exceeding the image. Take the following arguments:\n",
    "    - image: segmentation mask image to check.\n",
    "    - border: the percentage of pixels to consider as a border. 10% by default.\n",
    "    - tolerance: the percentage of tolerance for a lesion to be at the border of the image. 20% by default.\n",
    "    - warning: boolean to indicate if a textual warning should be issue when checking the border. True by default.\"\"\"\n",
    "    h = int(image.shape[0] * border)\n",
    "    w = int(image.shape[1] * border)\n",
    "    up = (np.sum(image[h,:]) / image.shape[1]) > tolerance\n",
    "    dw = (np.sum(image[-h,:]) / image.shape[1]) > tolerance\n",
    "    lt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    rt = (np.sum(image[:,w]) / image.shape[0]) > tolerance\n",
    "    if warning:\n",
    "        if up or dw or lt or rt: return \"This lesion might be overflowing the image\"\n",
    "        else: return \"This lesion does not seem to be overflowing the image\"\n",
    "    else:\n",
    "        return up or dw or lt or rt\n",
    "\n",
    "\n",
    "def masker(image, sens):\n",
    "    '''Takes image, converts to a grayscale image, and returns a masked \n",
    "    image that only shows values below the sensitivity given as input.'''\n",
    "    \n",
    "    gray = rgb2gray(image) # Create grayscale image\n",
    "    img2 = gray < sens # **This level needs manually adjusting, also need to be able to automate**\n",
    "    \n",
    "    # use plt.imshow(masker(image,sens), cmap='gray') to see image\n",
    "    \n",
    "    return img2.astype(int)\n",
    "\n",
    "def dimensions(mask1):\n",
    "    '''calculates height(max) and width(90 deg to height)\n",
    "        returns height, width, rotated mask image, degree of rotation'''\n",
    "    pixels_in_col = np.max(np.sum(mask1, axis=0))\n",
    "\n",
    "    rot = 0\n",
    "    max_col = 0\n",
    "    rot_max = 0\n",
    "    for _ in range(9):\n",
    "        rot_im = transform.rotate(mask1,rot)\n",
    "        pixels_in_col = np.max(np.sum(rot_im, axis=0))\n",
    "        if pixels_in_col > max_col:\n",
    "            max_col = pixels_in_col\n",
    "            rot_max = rot\n",
    "            pixels_in_row = np.max(np.sum(rot_im, axis=1))\n",
    "        rot += 10\n",
    "\n",
    "    return max_col, pixels_in_row, rot_max\n",
    "\n",
    "def measure_area_perimeter(mask):\n",
    "    \"\"\"A function that takes either a segmented image or perimeter \n",
    "    image as input, and calculates the length of the perimeter of a lesion.\"\"\"\n",
    "    \n",
    "    # Measure area: the sum of all white pixels in the mask image\n",
    "    area = np.sum(mask)\n",
    "\n",
    "    # Measure perimeter: first find which pixels belong to the perimeter.\n",
    "    perimeter = measure.perimeter(mask)\n",
    "    \n",
    "    return area, perimeter\n",
    "\n",
    "def predict(bi_image): # Predict might be a little confusing ?\n",
    "    \n",
    "    area = np.sum(bi_image)\n",
    "    _, peri = perimeter(bi_image)\n",
    "    \n",
    "    area_from_peri = pi*((peri/(2*pi))**2)\n",
    "    peri_from_area = 2*pi*sqrt(area/pi)\n",
    "    \n",
    "    return area, area_from_peri, peri, peri_from_area  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-terrorism",
   "metadata": {},
   "source": [
    "## Directories Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-clarity",
   "metadata": {},
   "source": [
    "(NOTE) We load and access the metadata included in our source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {} # A main dictionary will hold our different labels for datasets\n",
    "\n",
    "df['train'] = {'path': TRAIN, 'label': pd.read_csv(TRAIN + TRUTH, index_col='image_id')}\n",
    "df['validation'] = {'path': VALID, 'label': pd.read_csv(VALID + TRUTH, index_col='image_id')}\n",
    "df['test'] = {'path': TEST, 'label': pd.read_csv(TEST + TRUTH, index_col='image_id')}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-thermal",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (Task 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-density",
   "metadata": {},
   "source": [
    "## Dataset Cleaning and Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-biotechnology",
   "metadata": {},
   "source": [
    "#### Figure compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-latex",
   "metadata": {},
   "source": [
    "In order to work more efficiently, we decide to crop the images to reduce their dimensions to the part of the image that contains the lesion. For this, we will use our segmented masks, as following: the color images will be cropped to the rectangle where the lesion is, and saving the new image with reduced dimensions. This process must be done only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    i = 1\n",
    "    for k, v in df.items():\n",
    "        for img_id in v['label'].index:\n",
    "            imgpath = v['path'] + IMG + img_id + '.jpg'\n",
    "            mskpath = v['path'] + SEG + img_id + '_segmentation.png'\n",
    "            img = plt.imread(imgpath)\n",
    "            msk = plt.imread(mskpath)\n",
    "            new = crop(img, msk, warning=False)\n",
    "            if new is None:\n",
    "                pass\n",
    "            else: plt.imsave(imgpath, new)\n",
    "            print(f'\\rResizing image # {i}', end='\\r')\n",
    "            i += 1\n",
    "            \n",
    "else: print(\"OPERATION CANCELLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-contract",
   "metadata": {},
   "source": [
    "### We check for lesions overflowing the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-occupation",
   "metadata": {},
   "source": [
    "Here we go through the images and find those that are potentially too zoomed in and cut off areas of the border. Since this study focused on asymmetry and compactness of lesions, it is necessary to have images that show the entire border. \n",
    "\n",
    "The output is a list of images that are potentially cutting off the border. We then manually went through to verify the quality of the border in the images before excluding them from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We loop through all images applying our automatic border detection function\n",
    "\n",
    "WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "if WARN.lower().startswith(\"y\"):\n",
    "    with open('./to_check.csv', 'w') as outfile:\n",
    "        outfile.write('image_id'+','+'from Dataset'+'\\n')\n",
    "        for k, data in df.items():\n",
    "                for img_id in data['label'].index:\n",
    "                    img = plt.imread(data['path'] + SEG + img_id + '_segmentation.png') \n",
    "                    if check_border(img, warning=False) == True:\n",
    "                        outfile.write(img_id+','+data['path']+'\\n')\n",
    "else:\n",
    "    print(\"OPERATION CANCELLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After careful manual inspection, we read the file and filter the images to be ignored.\n",
    "# We then exclude them from our datasets.\n",
    "\n",
    "visual_inspection = pd.read_csv('./to_check.csv')\n",
    "to_be_ignored = visual_inspection[visual_inspection.loc[:,'Visual inspection'] == 'Ignore']\n",
    "mela, kera, non = 0,0,0\n",
    "for ix, row in to_be_ignored.iterrows():\n",
    "    try:\n",
    "        image = row.loc['image_id']\n",
    "        from_dataset = row.loc['from Dataset']\n",
    "        if df[from_dataset]['label'].loc[image,'melanoma'] == 1:\n",
    "            mela += 1\n",
    "        elif df[from_dataset]['label'].loc[image,'seborrheic_keratosis'] == 1:\n",
    "            kera += 1\n",
    "        else: non += 1\n",
    "        df[from_dataset]['label'].drop(image, axis=0, inplace=True)\n",
    "    except:\n",
    "        image = row.loc['image_id']\n",
    "        from_dataset = row.loc['from Dataset']\n",
    "        if df[from_dataset]['label'].loc[image,'melanoma'] == 1:\n",
    "            mela += 1\n",
    "        elif df[from_dataset]['label'].loc[image,'seborrheic_keratosis'] == 1:\n",
    "            kera += 1\n",
    "        else: non += 1\n",
    "            \n",
    "print(f'{to_be_ignored.shape[0]} images excluded from the model.')\n",
    "print(f'{mela} melanomas, {kera} keratosis and {non} benigns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-mobility",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-thursday",
   "metadata": {},
   "source": [
    "(NOTE) Here is shown how we visualize and mask the images to get familiar with the images and their attributes. The lesion images present in the dataset have been cropped and masked using the crop function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-demonstration",
   "metadata": {},
   "source": [
    "### Load Image and Segmentation Image Side-by-Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = 'ISIC_0000000'\n",
    "image = plt.imread(df['train']['path']+IMG+IM+'.jpg')\n",
    "seg = plt.imread(df['train']['path']+SEG+IM+'_segmentation.png')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(7, 5))\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(seg, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-village",
   "metadata": {},
   "source": [
    "### Showing how the zoom function works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-integer",
   "metadata": {},
   "source": [
    "This shows how the image was cropped so that the border is cut to the edges of the lesion, resulting in the cropped image of the lesion seen above on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(zoom(seg), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-longer",
   "metadata": {},
   "source": [
    "### Convert an image to grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-princess",
   "metadata": {},
   "source": [
    "This shows how the rgb2gray function works to convert an image to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb2gray(image), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-system",
   "metadata": {},
   "source": [
    "### VIsualize the masker function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-hollow",
   "metadata": {},
   "source": [
    "This function was written to create our own segmentation images. When the image has been masked with a segmentation image already, the function outputs differently. Since the images in this repository have all already been masked, it is not as clear to see how this functino would work. In addition, since we already had access to segmentation images, we did not further explore optimization of this technique for large amounts of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masker(image,140), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-novelty",
   "metadata": {},
   "source": [
    "### Visualize output of function for Area and Perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-tongue",
   "metadata": {},
   "source": [
    "This shows the output of the function that shows area and perimeter of a lesion, as well as a visual display of the perimeter of the lesion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "area, perimeter = measure_area_perimeter(seg)\n",
    "print(f'Area: {area}\\nPerimeter: {perimeter}')\n",
    "\n",
    "struct_el = morphology.disk(1)\n",
    "mask_eroded = morphology.binary_erosion(seg, struct_el)\n",
    "image_perimeter = seg - mask_eroded\n",
    "plt.imshow(image_perimeter, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-evans",
   "metadata": {},
   "source": [
    "### Output of the cuts function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-saturn",
   "metadata": {},
   "source": [
    "The output of this function is then used in the test_symmetry function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,d,l,r = cuts(seg)\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(5,3), dpi=350)\n",
    "ax1.imshow(u, cmap='gray')\n",
    "ax2.imshow(d, cmap='gray')\n",
    "ax3.imshow(l, cmap='gray')\n",
    "ax4.imshow(r, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-malta",
   "metadata": {},
   "source": [
    "### Result of the test_symmetry function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_symmetry(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-acrobat",
   "metadata": {},
   "source": [
    "This lesion shows a 76.65% symmetry, which lines up well with the visual symmetry of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-syndication",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-criminal",
   "metadata": {},
   "source": [
    "(NOTE) We proceed to extract features of interest for our predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-validity",
   "metadata": {},
   "source": [
    "#### Asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-affiliate",
   "metadata": {},
   "source": [
    "To test for asymmetry we run a function to calculate a score based on how similar an image is when cut horizontally and vertically. We assign a score between 0 (non asymmetric) and 1 (totally asymmetric) for both cuts, and we take the average to convey a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a test on a black circle, where it's symmetry should be close to 1\n",
    "test_circle = plt.imread('./data/test-black-circle.png') # Load the circle test\n",
    "test_circle = test_circle[:,:,0]\n",
    "print(f'Symmetry test for black circle: {test_symmetry(test_circle):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /symmetry.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        symmetry = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating symmetry: {ptg:.2%}', end='\\r')\n",
    "            symmetry[ix] = test_symmetry(image)\n",
    "            i += 1\n",
    "            %xdel image\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'symmetry_{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'symmetry'+'\\n')\n",
    "            for k, v in symmetry.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-homeless",
   "metadata": {},
   "source": [
    "#### Border (Compactness method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-tsunami",
   "metadata": {},
   "source": [
    "To test for border smoothness we use the compactness method. Compactness is defined as the ratio of the\n",
    "area of an object to the area of a circle with the same perimeter.\n",
    "The measure takes a maximum value of 1 for a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform a test on a black circle, where it's compactness should be close to 1\n",
    "circle_area, circle_perimeter = measure_area_perimeter(test_circle)\n",
    "circle_compactness = (4* math.pi * circle_area) / (circle_perimeter**2)\n",
    "print(f'Compactness test for black circle: {circle_compactness:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /compactness.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        compactness = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + SEG + str(ix) + \"_segmentation.png\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating compactness: {ptg:.2%}', end='\\r')\n",
    "            area, per = measure_area_perimeter(image)\n",
    "            compactness[ix] = (4* math.pi * area) / (per**2)\n",
    "            i += 1\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'compactness_{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'compactness'+'\\n')\n",
    "            for k, v in compactness.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-coast",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-knight",
   "metadata": {},
   "source": [
    "In order to evaluate the difference in lesion colors, we take the standard deviation for each of the 3 RGB channels of the cropped image (to reduce noise), and then we average the 3 deviations to obtain a unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = input(\"Which dataset to calculate? [train, validation, test] \")\n",
    "if DATASET.lower() not in ['train', 'validation', 'test']:\n",
    "    print('OPERATION CANCELLED')\n",
    "else:\n",
    "    data = df[DATASET]['label']\n",
    "\n",
    "    DoBatch = int(input(\"How many batches? \"))\n",
    "    if DoBatch > data.shape[0]:\n",
    "        DoBatch = data.shape[0]\n",
    "    batch = int(input(\"Do batch # \"))\n",
    "    assert batch <= DoBatch, \"Wrong Batch #\"\n",
    "\n",
    "    WARN = input(\"This operation may take several minutes. Do you wish to continue: (Yes/No) \")\n",
    "\n",
    "    REWRITE = input(\"Do you wish to overwrite the /color_deviation.csv file?: (Yes/No) \")\n",
    "    print(\"\\n----- PLEASE BE PATIENT -----\\n\")\n",
    "\n",
    "\n",
    "    length = data.shape[0] // DoBatch\n",
    "    start = length * (batch - 1)\n",
    "    end = length * (batch)\n",
    "\n",
    "    if WARN.lower().startswith(\"y\"):\n",
    "        color_deviation = {}\n",
    "        i = 1\n",
    "        for ix, row in data[start:end].iterrows():\n",
    "            file_path = df[DATASET]['path'] + IMG + str(ix) + \".jpg\"\n",
    "            image = plt.imread(file_path)\n",
    "\n",
    "            ptg = round(i / length,2)\n",
    "            print(f'\\rCalculating color deviation: {ptg:.2%}', end='\\r') \n",
    "            color_deviation[ix] = color_std(image)\n",
    "            i += 1\n",
    "    else: print(\"OPERATION CANCELLED\")\n",
    "\n",
    "    if REWRITE.lower().startswith(\"y\"):\n",
    "        with open(df[DATASET]['path'] + FEAT + f'color_deviation{str(batch)}.csv', 'w') as outfile:\n",
    "            outfile.write('image_id'+','+'color_deviation'+'\\n')\n",
    "            for k, v in color_deviation.items():\n",
    "                line = k +','+str(v)\n",
    "                outfile.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-relation",
   "metadata": {},
   "source": [
    "### Aggregating features to datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-present",
   "metadata": {},
   "source": [
    "We will now add the recently extracted features to our main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['symmetry', 'compactness', 'color_deviation']\n",
    "for dataset in df.keys():\n",
    "    for feat in feat_list:\n",
    "        symmetry = pd.read_csv(df[dataset]['path'] + FEAT + 'symmetry.csv', index_col='image_id') \n",
    "        compactness = pd.read_csv(df[dataset]['path'] + FEAT + 'compactness.csv', index_col='image_id')\n",
    "        color_deviation = pd.read_csv(df[dataset]['path'] + FEAT + 'color_deviation.csv', index_col='image_id')\n",
    "        df[dataset]['features'] = symmetry.merge(compactness, how = 'inner', on = 'image_id')\\\n",
    "        .merge(color_deviation, how = 'inner', on = 'image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train']['features'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-lebanon",
   "metadata": {},
   "source": [
    "### Analysis of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-willow",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-shame",
   "metadata": {},
   "source": [
    "As our features Symmetry and Compactness have a metric between zero and one, we will only scale the color deviation feature to match the same range as the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-conditioning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in df.keys():\n",
    "    scaled_color_deviation = []\n",
    "    to_scale = df[dataset]['features'].color_deviation\n",
    "    for i in to_scale.iteritems():\n",
    "        new_x = (i[1] - np.min(to_scale)) /\\\n",
    "        (np.max(to_scale) - np.min(to_scale))\n",
    "        scaled_color_deviation.append(new_x)\n",
    "    df[dataset]['features'].color_deviation = scaled_color_deviation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Dataframe with scaling\n",
    "df['train']['features'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df['train']['label'].merge(df['train']['features'], how = 'inner', on = 'image_id')\n",
    "train_set.drop('seborrheic_keratosis', axis= 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.loc[train_set.melanoma == 1, 'melanoma'] = \"Melanoma\"\n",
    "train_set.loc[train_set.melanoma == 0, 'melanoma'] = \"Non-Melanoma\"\n",
    "train_set.columns = ['label'] + list(train_set.columns)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-quest",
   "metadata": {},
   "source": [
    "#### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "melanoma = train_set.loc[train_set.label == \"Melanoma\"]\n",
    "n = train_set.shape[0]//2 - melanoma.shape[0] # We want 1/3 to be melanoma\n",
    "resample_melanoma = resample(melanoma, n_samples=n)\n",
    "train_set_rs = train_set.append(resample_melanoma)\n",
    "print(f'The new training set contains now {train_set_rs[train_set_rs.label == \"Melanoma\"].shape[0]}\\\n",
    " Melanoma observations and {train_set_rs[train_set_rs.label != \"Melanoma\"].shape[0]}\\\n",
    " non Melanoma observations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-afghanistan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2, figsize=(15,12), dpi=350)\n",
    "fig.suptitle(\"Scatterplots of Lesion Features\")\n",
    "fig.tight_layout(h_pad=2)\n",
    "i = 0\n",
    "for f1 in feat_list:\n",
    "    for f2 in feat_list:\n",
    "        if f1 != f2:\n",
    "            if i < 3:\n",
    "                axis = (i, 0)\n",
    "            else:\n",
    "                axis = (i-3, 1)\n",
    "            ax[0,0] = sns.scatterplot(x=f1, y=f2, data=train_set_rs, hue='label', ax=ax[axis])\n",
    "            i += 1\n",
    "#plt.show()\n",
    "plt.savefig(\"./reports/figures/features_scatter.png\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = train_set_rs.loc[train_set_rs.label == \"Melanoma\"]\n",
    "negative = train_set_rs.loc[train_set_rs.label == \"Non-Melanoma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(7,5), dpi=350)\n",
    "fig.suptitle(\"Melanoma Vs Non-Melanoma Feature Distributions\")\n",
    "fig.tight_layout()\n",
    "\n",
    "sns.kdeplot(x = 'symmetry', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\",ax=axs[0])\n",
    "sns.kdeplot(x = 'symmetry', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\",ax=axs[0])\n",
    "axs[0].axvline(np.mean(positive.symmetry), ymin= 0, ymax= 0.78, color='r', linestyle = 'dashed')\n",
    "axs[0].axvline(np.mean(negative.symmetry), ymin= 0, ymax= 0.80, color='g', linestyle = 'dashed')\n",
    "axs[0].legend(loc=\"upper left\")\n",
    "\n",
    "sns.kdeplot(x = 'compactness', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\",ax=axs[1])\n",
    "sns.kdeplot(x = 'compactness', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\",ax=axs[1])\n",
    "axs[1].axvline(np.mean(positive.compactness), ymin= 0, ymax= 0.67, color='r', linestyle = 'dashed')\n",
    "axs[1].axvline(np.mean(negative.compactness), ymin= 0, ymax= 0.80, color='g', linestyle = 'dashed')\n",
    "#axs[1].legend(loc=\"upper left\")\n",
    "\n",
    "sns.kdeplot(x = 'color_deviation', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\",ax=axs[2])\n",
    "sns.kdeplot(x = 'color_deviation', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\",ax=axs[2])\n",
    "axs[2].axvline(np.mean(positive.color_deviation), ymin= 0, ymax= 0.77, color='r', linestyle = 'dashed')\n",
    "axs[2].axvline(np.mean(negative.color_deviation), ymin= 0, ymax= 0.88, color='g', linestyle = 'dashed')\n",
    "#axs[2].legend(loc=\"upper right\")\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"./reports/figures/densitySubplots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=250)\n",
    "fig.suptitle(\"Melanoma Vs Non-Melanoma Symmetry Density \")\n",
    "fig.tight_layout()\n",
    "\n",
    "sns.kdeplot(x = 'symmetry', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\")\n",
    "sns.kdeplot(x = 'symmetry', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\")\n",
    "ax.axvline(np.mean(positive.symmetry), ymin= 0, ymax= 0.78, color='r', linestyle = 'dashed')\n",
    "ax.axvline(np.mean(negative.symmetry), ymin= 0, ymax= 0.80, color='g', linestyle = 'dashed');\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig(\"./reports/figures/sym_density.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-spending",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=250)\n",
    "fig.suptitle(\"Melanoma Vs Non-Melanoma Compactness Density\")\n",
    "fig.tight_layout()\n",
    "\n",
    "sns.kdeplot(x = 'compactness', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\")\n",
    "sns.kdeplot(x = 'compactness', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\")\n",
    "ax.axvline(np.mean(positive.compactness), ymin= 0, ymax= 0.67, color='r', linestyle = 'dashed')\n",
    "ax.axvline(np.mean(negative.compactness), ymin= 0, ymax= 0.80, color='g', linestyle = 'dashed');\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig(\"./reports/figures/compact_density.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=250)\n",
    "fig.suptitle(\"Melanoma Vs Non-Melanoma Color Density\")\n",
    "fig.tight_layout()\n",
    "\n",
    "sns.kdeplot(x = 'color_deviation', data=positive, cumulative= False, shade=True, clip=(0,1), color='r',label=\"Melanoma\")\n",
    "sns.kdeplot(x = 'color_deviation', data=negative, cumulative= False, shade=True, clip=(0,1), color='g',label=\"Non-Melanoma\")\n",
    "ax.axvline(np.mean(positive.color_deviation), ymin= 0, ymax= 0.77, color='r', linestyle = 'dashed')\n",
    "ax.axvline(np.mean(negative.color_deviation), ymin= 0, ymax= 0.88, color='g', linestyle = 'dashed');\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.savefig(\"./reports/figures/color_density.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-family",
   "metadata": {},
   "source": [
    "From the plots is difficult to see any correlation. We will take each feature by pairs and see if they are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Melanoma, the features have the following correlation coefficients:\\n')\n",
    "feat_iter = feat_list.copy()\n",
    "for f1 in feat_iter:\n",
    "    for f2 in feat_iter:\n",
    "        if f1 != f2:\n",
    "            corr = np.corrcoef(positive[f1], positive[f2])\n",
    "            print(f'Corr. {f1} and {f2}: {corr[0,1]:.2%}')\n",
    "    feat_iter.remove(f1)\n",
    "    \n",
    "print('\\nFor Non-Melanoma, the features have the following correlation coefficients:\\n')\n",
    "feat_iter = feat_list.copy()\n",
    "for f1 in feat_iter:\n",
    "    for f2 in feat_iter:\n",
    "        if f1 != f2:\n",
    "            corr = np.corrcoef(negative[f1], negative[f2])\n",
    "            print(f'Corr. {f1} and {f2}: {corr[0,1]:.2%}')\n",
    "    feat_iter.remove(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-receipt",
   "metadata": {},
   "source": [
    "We see a positive correlation between features for Melanoma lesions, but smaller correlations for Non-Melanoma, with even a negative correlation between Symmetry and Color Deviation. Should we take another approach in our splitting of Melanoma/Non-Melanoma?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-subject",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-universe",
   "metadata": {},
   "source": [
    "We first create the set with features and labels for validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Validation Data\n",
    "validation_set = df['validation']['label'].merge(df['validation']['features'],\\\n",
    "                                                 how = 'inner', on = 'image_id')\n",
    "\n",
    "# For Test Data\n",
    "test_set = df['test']['label'].merge(df['test']['features'], how = 'inner', on = 'image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for ix, row in validation_set.iterrows():\n",
    "    if row['melanoma'] == 1.0:\n",
    "        labels.append(\"Melanoma\")\n",
    "    else:\n",
    "        labels.append(\"Non-Melanoma\")\n",
    "        \n",
    "validation_set['label'] = labels\n",
    "validation_set.drop(\"melanoma\", axis=1, inplace=True)\n",
    "validation_set.drop(\"seborrheic_keratosis\", axis=1, inplace=True)  \n",
    "\n",
    "labels = []\n",
    "for ix, row in test_set.iterrows():\n",
    "    if row['melanoma'] == 1.0:\n",
    "        labels.append(\"Melanoma\")\n",
    "    else:\n",
    "        labels.append(\"Non-Melanoma\")\n",
    "        \n",
    "test_set['label'] = labels\n",
    "test_set.drop(\"melanoma\", axis=1, inplace=True)\n",
    "test_set.drop(\"seborrheic_keratosis\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move the label column to the last place to match the other datasets\n",
    "cols = list(train_set_rs.columns)\n",
    "cols = cols[1:] + [cols[0]]\n",
    "train_set_rs = train_set_rs[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_rs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-chuck",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training Data\n",
    "X_train = train_set_rs.iloc[:,:-1].reset_index(drop=True).values\n",
    "y_train = train_set_rs.iloc[:,-1].reset_index(drop=True).values\n",
    "\n",
    "# For Validation Data\n",
    "X_valid = validation_set.iloc[:,:-1].reset_index(drop=True).values\n",
    "y_valid = validation_set.iloc[:,-1].reset_index(drop=True).values\n",
    "\n",
    "# For Test Data\n",
    "X_test = test_set.iloc[:,:-1].reset_index(drop=True).values\n",
    "y_test = test_set.iloc[:,-1].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-toolbox",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-browse",
   "metadata": {},
   "source": [
    "#### Selecting best K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-sewing",
   "metadata": {},
   "source": [
    "We will try the model on a different range of Ks to find the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_KNN = []\n",
    "\n",
    "# Calculating score for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    pred_i = KNN.predict(X_valid)\n",
    "    scores_KNN.append(recall_score(y_valid, pred_i, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), scores_KNN, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='green', markersize=8)\n",
    "plt.title('Scores for K Values')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Model Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = [i for i, x in enumerate(scores_KNN) if x == max(scores_KNN)]\n",
    "best_k[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-ratio",
   "metadata": {},
   "source": [
    "#### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=best_k[0])\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-chile",
   "metadata": {},
   "source": [
    "#### Model prediction on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_KNN = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_KNN))\n",
    "print(f'Overall Model Accuracy: {accuracy_score(y_test, y_pred_KNN):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-climate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(KNN, X_test, y_test,\n",
    "                                 display_labels=['Melanoma', \"Non-Melanoma\"],\n",
    "                                 cmap=plt.cm.Blues);\n",
    "disp.ax_.set_title(\"Quality of KNN Classifier\")\n",
    "plt.savefig(\"./reports/figures/knnConfMat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-orientation",
   "metadata": {},
   "source": [
    "PRECISION: is the ability of a classifier not to label an instance positive that is actually negative. For each class it is defined as the ratio of true positives to the sum of true and false positives.\n",
    "\n",
    "TP  True Positives\n",
    "FP  False Positives\n",
    "\n",
    "Precision  Accuracy of positive predictions.\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "Our model achieved a precision of 0.16 for Melanoma and 0.80 for Non-Melanoma, with a joint accuracy of 73.50 %.\n",
    "\n",
    "---------\n",
    "\n",
    "RECALL: is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.\n",
    "\n",
    "FN  False Negatives\n",
    "\n",
    "Recall: Fraction of positives that were correctly identified.\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "Our model did not perform specially well on predicting Melanoma instances.\n",
    "\n",
    "---------\n",
    "\n",
    "The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-lyric",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeClassifier(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_DT))\n",
    "print(f'Overall Model Accuracy: {accuracy_score(y_test, y_pred_DT):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(DT, X_test, y_test,\n",
    "                                 display_labels=['Melanoma', \"Non-Melanoma\"],\n",
    "                                 cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title(\"Quality of Decision Tree Classifier\")\n",
    "plt.savefig(\"./reports/figures/deciTreeConfMat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-involvement",
   "metadata": {},
   "source": [
    "Our Decision Tree model performs a little better than the KNN, with 19% of true melanomas detected and 81% of non-melanoma correctly detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = RF.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(RF, X_valid, y_valid,\n",
    "                                 display_labels=['Melanoma', 'Non-Melanoma'],\n",
    "                                 cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-chain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-optimum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-measure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
